{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import umap\n",
    "import hdbscan\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def docvec(model):\n",
    "    # docs = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))['data']\n",
    "    # docs = docs[0:100]\n",
    "    with open('../articles_data/all_articles_with_thumbnail_metadata.json') as f:\n",
    "        papers = json.load(f)\n",
    "\n",
    "    docs = [paper['article_title'] + ' ' + paper['abstract'] for paper in papers]\n",
    "    doc_titles = [paper['article_title'] for paper in papers]\n",
    "\n",
    "\n",
    "    embeddings = model.encode(docs, show_progress_bar=True)\n",
    "\n",
    "    umap_embeddings = umap.UMAP(n_neighbors=5,\n",
    "                                n_components=5,\n",
    "                                metric='cosine').fit_transform(embeddings)\n",
    "\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=3,\n",
    "                              metric='euclidean',\n",
    "                              cluster_selection_method='eom').fit(umap_embeddings)\n",
    "\n",
    "\n",
    "\n",
    "    # Prepare data\n",
    "    umap_data = umap.UMAP(n_neighbors=5, n_components=2, metric='cosine').fit_transform(embeddings)\n",
    "    result = pd.DataFrame(umap_data, columns=['x', 'y'])\n",
    "    result['labels'] = cluster.labels_\n",
    "    result['titles'] = doc_titles\n",
    "    print(cluster.labels_.max())\n",
    "\n",
    "\n",
    "    docs_df = pd.DataFrame(docs, columns=[\"Doc\"])\n",
    "    docs_df['Topic'] = cluster.labels_\n",
    "    docs_df['Titles'] = doc_titles\n",
    "    docs_df['Doc_ID'] = range(len(docs_df))\n",
    "    docs_per_topic = docs_df.groupby(['Topic'], as_index=False).agg({'Doc': ' '.join})\n",
    "    return result,cluster, docs, docs_df, docs_per_topic"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = SentenceTransformer('allenai-specter')\n",
    "\n",
    "result,cluster, docs, docs_df, docs_per_topic = docvec(model)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def c_tf_idf(documents, m, ngram_range=(1, 1)):\n",
    "    count = CountVectorizer(ngram_range=ngram_range, stop_words=\"english\").fit(documents)\n",
    "    t = count.transform(documents).toarray()\n",
    "    w = t.sum(axis=1)\n",
    "    tf = np.divide(t.T, w)\n",
    "    sum_t = t.sum(axis=0)\n",
    "    idf = np.log(np.divide(m, sum_t)).reshape(-1, 1)\n",
    "    tf_idf = np.multiply(tf, idf)\n",
    "\n",
    "    return tf_idf, count"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "tf_idf, count = c_tf_idf(docs_per_topic.Doc.values, m=len(docs))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def extract_top_n_words_per_topic(tf_idf, count, docs_per_topic, n):\n",
    "    words = count.get_feature_names()\n",
    "    labels = list(docs_per_topic.Topic)\n",
    "    tf_idf_transposed = tf_idf.T\n",
    "    indices = tf_idf_transposed.argsort()[:, -n:]\n",
    "    top_n_words = {label: [words[j] for j in indices[i]][::-1] for i, label in enumerate(labels)}\n",
    "    return top_n_words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def extract_topic_sizes(df):\n",
    "    topic_sizes = (df.groupby(['Topic'])\n",
    "                     .Doc\n",
    "                     .count()\n",
    "                     .reset_index()\n",
    "                     .rename({\"Topic\": \"Topic\", \"Doc\": \"Size\"}, axis='columns')\n",
    "                     .sort_values(\"Size\", ascending=False))\n",
    "    return topic_sizes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{-1: ['bird', 'transfer', 'activation', 'labeling', 'labels', 'ablation'], 0: ['flow', 'cardiac', 'pc', 'heart', '4d', 'mri'], 1: ['connectivity', 'functional', 'neurons', 'networks', 'network', 'fu'], 2: ['molecular', 'protein', 'proteins', 'molecule', 'molecules', 'tunnels'], 3: ['cta', 'arteries', 'artery', 'cerebral', 'vessels', 'cow'], 4: ['deep', 'learning', 'mitotic', 'mammogram', 'mg', 'classification'], 5: ['analytics', 'pathologists', 'pathology', 'thermal', 'digital', 'diagnostic'], 6: ['fiber', 'tractography', 'crossing', 'tracts', 'diffusion', 'white'], 7: ['tensor', 'diffusion', 'maze', 'uncertainty', 'formation', 'groups'], 8: ['motion', 'registration', 'lung', 'correction', 'mean', 'physiological'], 9: ['valve', 'stress', 'implant', 'mitral', 'residual', 'bone'], 10: ['reality', 'display', 'xr', 'vr', 'ar', 'simulator'], 11: ['ultrasound', 'hifu', 'mode', 'liver', 'tracing', 'ray'], 12: ['evaluations', 'biomedical', 'communication', 'evaluation', 'practice', 'preferences'], 13: ['tumor', 'ius', 'pet', 'growth', 'roi', 'registration'], 14: ['segmentation', 'shape', 'surface', 'mesh', 'uncertainty', 'segmentations'], 15: ['projection', 'textures', 'distortions', 'projections', 'wdt', 'solid'], 16: ['vascular', 'vessel', 'blood', 'aneurysm', 'lumen', 'vessels']}\n",
      "210\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "hovertemplate": "<b>%{hovertext}</b><br><br>Topics=molecular.protein.proteins.molecule.molecules.tunnels<br>x=%{x}<br>y=%{y}<extra></extra>",
         "hovertext": [
          "Interactive Exploded Views for Molecular Structures",
          "Atomistic Visualization of Mesoscopic Whole-Cell Simulations",
          "Watergate: Visual Exploration of Water Trajectories in Protein Dynamics",
          "cellVIEW: a Tool for Illustrative and Multi-Scale Rendering of Large Biomolecular Datasets",
          "Visual Analysis and Comparison of Multiple Sequence Alignments",
          "Membrane Mapping: Combining Mesoscopic and Molecular Cell Visualization",
          "Analyzing Protein Similarity by Clustering Molecular Surface Maps",
          "A Haptic Rendering Algorithm for Molecular Interaction",
          "Real-Time Visualization of 3D Amyloid-Beta Fibrils from 2D Cryo-EM Density Maps",
          "Unfolding and Interactive Exploration of Protein Tunnels and their Dynamics",
          "DockVis: Visual Analysis of Molecular Docking Data",
          "Protein Tunnel Reprojection for Physico-Chemical Property Analysis",
          "Interactive CPU-based Ray Tracing of Solvent Excluded Surfaces",
          "Visualization and Exploration of 3D Toponome Data",
          "Computation of More Channels in Protein Molecules",
          "Visual Analysis of Bipartite Biological Networks",
          "Illustrative Transitions in Molecular Visualization via Forward and Inverse Abstraction Transform",
          "Hybrid Visualization of Protein-Lipid and Protein-Protein Interaction",
          "Molecular Sombreros: Abstract Visualization of Binding Sites within Proteins",
          "Chameleon - Dynamic Color Mapping for Multi-Scale Structural Biology Models",
          "Instant Visualization of Secondary Structures of Molecular Models",
          "Visualizing Movements of Protein Tunnels in Molecular Dynamics Simulations",
          "FoldSynth: Interactive 2D/3D Visualisation Platform for Molecular Strands",
          "FluoroSim: A Visual Problem-Solving Environment for Fluorescence Microscopy",
          "Improving Perception of Molecular Surface Visualizations by Incorporating Translucency Effects",
          "Real-Time Dense Nucleus Selection from Confocal Data",
          "Semantic Screen-Space Occlusion for Multiscale Molecular Visualization"
         ],
         "legendgroup": "molecular.protein.proteins.molecule.molecules.tunnels",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "molecular.protein.proteins.molecule.molecules.tunnels",
         "orientation": "v",
         "showlegend": true,
         "x": [
          11.353458404541016,
          11.112112998962402,
          11.513835906982422,
          11.24240779876709,
          11.486777305603027,
          10.96341323852539,
          11.436065673828125,
          11.427106857299805,
          11.040488243103027,
          11.525171279907227,
          11.570666313171387,
          11.77976131439209,
          11.007094383239746,
          10.274176597595215,
          11.808584213256836,
          11.275152206420898,
          10.982041358947754,
          11.378890991210938,
          11.496362686157227,
          10.44150161743164,
          11.285989761352539,
          11.752182960510254,
          11.324108123779297,
          10.824968338012695,
          10.879570007324219,
          10.270232200622559,
          10.431352615356445
         ],
         "xaxis": "x",
         "y": [
          6.531891345977783,
          5.932096004486084,
          6.844592094421387,
          6.18428897857666,
          7.280216693878174,
          5.841034412384033,
          7.2732768058776855,
          6.417327880859375,
          5.786619186401367,
          6.956653594970703,
          7.149440765380859,
          7.043140888214111,
          5.929601669311523,
          6.059593677520752,
          7.032642364501953,
          6.9299702644348145,
          6.569153308868408,
          6.810847282409668,
          7.240987777709961,
          6.238524913787842,
          6.2454633712768555,
          6.835847854614258,
          6.50663948059082,
          5.598160743713379,
          5.951852798461914,
          4.882491588592529,
          6.164299011230469
         ],
         "yaxis": "y",
         "type": "scatter"
        },
        {
         "hovertemplate": "<b>%{hovertext}</b><br><br>Topics=projection.textures.distortions.projections.wdt.solid<br>x=%{x}<br>y=%{y}<extra></extra>",
         "hovertext": [
          "Layer-Aware iOCT Volume Rendering for Retinal Surgery",
          "Anatomical Volume Visualization with Weighted Distance Fields",
          "VisualFlatter - Visual Analysis of Distortions in the Projection of Biomedical Structures",
          "Model-based Solid Texture Synthesis for Anatomic Volume Illustration",
          "Volume Visualization Using Principal Component Analysis"
         ],
         "legendgroup": "projection.textures.distortions.projections.wdt.solid",
         "marker": {
          "color": "#EF553B",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "projection.textures.distortions.projections.wdt.solid",
         "orientation": "v",
         "showlegend": true,
         "x": [
          4.5864739418029785,
          4.885083198547363,
          5.43342924118042,
          4.297755241394043,
          4.932013034820557
         ],
         "xaxis": "x",
         "y": [
          6.019912242889404,
          5.6325578689575195,
          5.255282402038574,
          5.578217029571533,
          5.768516540527344
         ],
         "yaxis": "y",
         "type": "scatter"
        },
        {
         "hovertemplate": "<b>%{hovertext}</b><br><br>Topics=analytics.pathologists.pathology.thermal.digital.diagnostic<br>x=%{x}<br>y=%{y}<extra></extra>",
         "hovertext": [
          "Introducing CNN-Based Mouse Grim Scale Analysis for Fully Automated Image-Based Assessment of Distress in Laboratory Mice",
          "PerSleep: A Visual Analytics Approach for Performance Assessment of Sleep Staging Models",
          "PATHONE: From one Thousand Patients to one Cell",
          "Visual Analytics in Histopathology Diagnostics: a Protocol-Based Approach",
          "Discovering Medical Knowledge Using Visual Analytics",
          "preha: Establishing Precision Rehabilitation with Visual Analytics",
          "Visual Analytics in Digital Pathology: Challenges and Opportunities",
          "Visual Analytics of Missing Data in Epidemiological Cohort Studies",
          "SWiFT Seeing the Wood From the Trees: helping people make sense of their health data",
          "Visual Analysis of Multivariate Intensive Care Surveillance Data",
          "Inlier Detection in Thermal Sensitive Images",
          "GLANCE: Visual Analytics for Monitoring Glaucoma Progression",
          "A Visual Analytics Approach for Patient Stratification and Biomarker Discovery",
          "Multiple Scale Visualization of Electronic Health Records to Support Finding Medical Narratives"
         ],
         "legendgroup": "analytics.pathologists.pathology.thermal.digital.diagnostic",
         "marker": {
          "color": "#00cc96",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "analytics.pathologists.pathology.thermal.digital.diagnostic",
         "orientation": "v",
         "showlegend": true,
         "x": [
          8.095111846923828,
          8.143762588500977,
          8.337512969970703,
          8.36275863647461,
          8.238160133361816,
          8.37795352935791,
          8.253508567810059,
          8.03293514251709,
          8.373919486999512,
          7.923770427703857,
          7.508171081542969,
          8.228536605834961,
          8.038070678710938,
          8.361105918884277
         ],
         "xaxis": "x",
         "y": [
          1.2424747943878174,
          1.4833321571350098,
          1.033328890800476,
          1.1142884492874146,
          1.5583330392837524,
          1.7313401699066162,
          1.311887264251709,
          1.6081548929214478,
          1.7053402662277222,
          1.5169579982757568,
          1.4046655893325806,
          1.3522526025772095,
          1.5544962882995605,
          1.7230041027069092
         ],
         "yaxis": "y",
         "type": "scatter"
        },
        {
         "hovertemplate": "<b>%{hovertext}</b><br><br>Topics=reality.display.xr.vr.ar.simulator<br>x=%{x}<br>y=%{y}<extra></extra>",
         "hovertext": [
          "VR Acrophobia Treatment - Development of Customizable Acrophobia Inducing Scenarios",
          "Student and Teacher Meet in a Shared Virtual Reality: A one-on-one Tutoring System for Anatomy Education",
          "Real-Time Guidance and Anatomical Information by Image Projection onto Patients",
          "Exploration of 3D Medical Image Data for Interventional Radiology using Myoelectric Gesture Control",
          "Visual Navigation Support for Liver Applicator Placement using Interactive Map Displays",
          "Haptics-based Modelling of Pigmented Skin Lesions",
          "A Prototype Holographic Augmented Reality Interface for Image-Guided Prostate Cancer Interventions",
          "An Endoscope Interface for Immersive Virtual Reality",
          "Simulation-based Ultrasound Training Supported by Annotations, Haptics and Linked Multimodal Views",
          "A Comparative User Study of a 2D and an Autostereoscopic 3D Display for a Tympanoplastic Surgery",
          "ICG based Augmented-Reality-System for Sentinel Lymph Node Biopsy",
          "The Role of Depth Perception in XR from a Neuroscience Perspective: A Primer and Survey",
          "QuantiScale: A Study in Redesigning Interactions for Multi-Touch",
          "Learning Hand Anatomy with Sense of Embodiment",
          "A Haptics-enabled Simulator for Transperineal Ultrasound-Guided Biopsy",
          "Challenges and Technologies for Low Cost Wheelchair Simulation",
          "AR-Assisted Craniotomy Planning for Tumour Resection"
         ],
         "legendgroup": "reality.display.xr.vr.ar.simulator",
         "marker": {
          "color": "#ab63fa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "reality.display.xr.vr.ar.simulator",
         "orientation": "v",
         "showlegend": true,
         "x": [
          -0.15456660091876984,
          0.055098604410886765,
          0.40030503273010254,
          0.6294278502464294,
          0.8374735116958618,
          0.41181501746177673,
          0.28528454899787903,
          0.1146928071975708,
          0.742165744304657,
          0.7479794025421143,
          0.42694607377052307,
          0.8408085107803345,
          0.628268837928772,
          -0.031119532883167267,
          0.3179212808609009,
          -0.06460881233215332,
          0.5496626496315002
         ],
         "xaxis": "x",
         "y": [
          3.3537180423736572,
          3.2239298820495605,
          3.267148017883301,
          2.612415313720703,
          3.315467119216919,
          2.5433151721954346,
          2.880283832550049,
          3.1742827892303467,
          2.684331178665161,
          2.874549388885498,
          3.0263850688934326,
          2.942121744155884,
          2.6263747215270996,
          3.395559787750244,
          2.621673583984375,
          3.3224847316741943,
          3.0001699924468994
         ],
         "yaxis": "y",
         "type": "scatter"
        },
        {
         "hovertemplate": "<b>%{hovertext}</b><br><br>Topics=tensor.diffusion.maze.uncertainty.formation.groups<br>x=%{x}<br>y=%{y}<extra></extra>",
         "hovertext": [
          "Visual Exploratory Analysis for Multiple T-Maze Studies",
          "Interactive Formation of Statistical Hypotheses in Diffusion Tensor Imaging",
          "Comparative Visualization for Diffusion Tensor Imaging Group Study at Multiple Levels of Detail",
          "Interactive Multimodal Imaging Visualization for Multiple Sclerosis Lesion Analysis",
          "SpectraMosaic: An Exploratory Tool for the Interactive Visual Analysis of Magnetic Resonance Spectroscopy Data",
          "A Survey on Visualizing Magnetic Resonance Spectroscopy Data",
          "Deriving and Visualizing Uncertainty in Kinetic PET Modeling",
          "MedUse: A Visual Analysis Tool for Medication Use Data in the ABCD Study",
          "A Visual Environment for Hypothesis Formation and Reasoning in Studies with fMRI and Multivariate Clinical Data"
         ],
         "legendgroup": "tensor.diffusion.maze.uncertainty.formation.groups",
         "marker": {
          "color": "#FFA15A",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "tensor.diffusion.maze.uncertainty.formation.groups",
         "orientation": "v",
         "showlegend": true,
         "x": [
          7.230952262878418,
          7.167733669281006,
          7.101341247558594,
          7.053091526031494,
          7.547104835510254,
          7.441543102264404,
          7.314080715179443,
          7.699601173400879,
          7.645349979400635
         ],
         "xaxis": "x",
         "y": [
          3.013587474822998,
          2.8900609016418457,
          2.903024673461914,
          2.7751667499542236,
          2.0227277278900146,
          1.8272175788879395,
          1.8435899019241333,
          2.050260305404663,
          2.126694440841675
         ],
         "yaxis": "y",
         "type": "scatter"
        },
        {
         "hovertemplate": "<b>%{hovertext}</b><br><br>Topics=cta.arteries.artery.cerebral.vessels.cow<br>x=%{x}<br>y=%{y}<extra></extra>",
         "hovertext": [
          "CoWRadar: Visual Quantification of the Circle of Willis in Stroke Patients",
          "A New Vessel Enhancement Transform on Retinal Blood Vessels Segmentation",
          "Histology-Based Evaluation of Optical Coherence Tomographic Characteristics of the Cerebral Artery Wall via Virtual Inflating",
          "VirtualDSA++: Automated Segmentation, Vessel Labeling, Occlusion Detection and Graph Search on CT-Angiography Data",
          "Automatic Thrombus Detection in Non-enhanced Computed Tomography Images in Patients With Acute Ischemic Stroke",
          "A Two-Level Cascade Classification Algorithm for Real-Time Bifurcation Detection in CTA Images of Blood Vessels",
          "Automated Slice-Based Artery Identification in Various Field-of-View CTA Scans"
         ],
         "legendgroup": "cta.arteries.artery.cerebral.vessels.cow",
         "marker": {
          "color": "#19d3f3",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "cta.arteries.artery.cerebral.vessels.cow",
         "orientation": "v",
         "showlegend": true,
         "x": [
          1.857552170753479,
          1.5877735614776611,
          2.1502737998962402,
          1.6897293329238892,
          1.5963013172149658,
          1.600284457206726,
          1.6439483165740967
         ],
         "xaxis": "x",
         "y": [
          5.731562614440918,
          5.792247772216797,
          5.880738258361816,
          5.7284111976623535,
          5.735196113586426,
          5.771534442901611,
          5.764368534088135
         ],
         "yaxis": "y",
         "type": "scatter"
        },
        {
         "hovertemplate": "<b>%{hovertext}</b><br><br>Topics=segmentation.shape.surface.mesh.uncertainty.segmentations<br>x=%{x}<br>y=%{y}<extra></extra>",
         "hovertext": [
          "Automatic Segmentation of the Pelvic Bones from CT Data Based on a Statistical Shape Model",
          "Estimation of the Midsagittal Plane for Sideness Determination of Malignant Structures of Head and Neck",
          "A Multilinear Model for Bidirectional Craniofacial Reconstruction",
          "Sketch-based Image-independent Editing of 3D Tumor Segmentations using Variational Interpolation",
          "Uncertainty-aware Brain Lesion Visualization",
          "Bone Fracture and Lesion Assessment using Shape-Adaptive Unfolding",
          "Polar Space Based Shape Averaging for Star-shaped Biological Objects",
          "Visually Guided Mesh Smoothing for Medical Applications",
          "Robust Classification and Analysis of Anatomical Surfaces Using 3D Skeletons",
          "Fast and Smooth Interactive Segmentation of Medical Images Using Variational Interpolation",
          "A Statistical Method for Surface Detection",
          "A General Approach to Model Biomedical Data from 3D Unorganised Point Clouds with Medial Scaffolds",
          "Visual Analysis of Medical Image Segmentation Feature Space for Interactive Supervised Classification",
          "Colonic Content Assessment from MRI Imaging Using a Semi-automatic Approach",
          "Evaluation of Hippocampal Segmentation Methods for Healthy and Pathological Subjects",
          "Fully Automatic Skull-Stripping in 3D Time-of-Flight MRA Image Sequences",
          "Extracting and Visualizing Uncertainties in Segmentations from 3D Medical Data",
          "Uncertainty-aware Ensemble of Classifiers for Segmenting Brain MRI Data",
          "Impact of Physical Noise Modeling on Image Segmentation in Echocardiography",
          "Uncertainty Estimation and Visualization for Multi-modal Image Segmentation",
          "MRI Hip Joint Segmentation: A Locally Bhattacharyya Weighted Hybrid 3D Level Set Approach",
          "Global and Local Mesh Morphing for Complex Biological Objects from ÂµCT Data",
          "Surface Curvature Line Clustering for Polyp Detection in CT Colonography",
          "Staircase-Aware Smoothing of Medical Surface Meshes",
          "Visual Analytics for the Exploration and Assessment of Segmentation Errors",
          "Parametric-based Reconstruction Of 3D Mesh Models; Towards the Generation of a Parametric Human Foot Biomodel",
          "Uncertainty-Guided Semi-Automated Editing of CNN-based Retinal Layer Segmentations in Optical Coherence Tomography",
          "UI-Net: Interactive Artificial Neural Networks for Iterative Image Segmentation Based on a User Model",
          "A Feasibility Study on Automated Protein Aggregate Characterization Utilizing a Hybrid Classification Model",
          "InShaDe: Invariant Shape Descriptors for Visual Analysis of Histology 2D Cellular and Nuclear Shapes"
         ],
         "legendgroup": "segmentation.shape.surface.mesh.uncertainty.segmentations",
         "marker": {
          "color": "#FF6692",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "segmentation.shape.surface.mesh.uncertainty.segmentations",
         "orientation": "v",
         "showlegend": true,
         "x": [
          4.136600971221924,
          4.257655620574951,
          2.9680378437042236,
          3.6068575382232666,
          4.713891983032227,
          4.15390682220459,
          4.1333746910095215,
          3.6982662677764893,
          3.191981315612793,
          3.709463596343994,
          3.5820164680480957,
          2.879034996032715,
          5.031764030456543,
          4.054015159606934,
          4.246856689453125,
          3.8068621158599854,
          3.869990110397339,
          4.444282531738281,
          3.168189764022827,
          4.596737861633301,
          3.634754180908203,
          2.77421498298645,
          4.210100173950195,
          3.712059497833252,
          4.969600200653076,
          2.3823115825653076,
          5.183164119720459,
          5.148957252502441,
          10.214855194091797,
          4.474748611450195
         ],
         "xaxis": "x",
         "y": [
          2.449707269668579,
          3.860448122024536,
          4.140015125274658,
          3.670257806777954,
          3.399951457977295,
          2.6794986724853516,
          3.2411012649536133,
          3.553194999694824,
          4.005304336547852,
          3.6797280311584473,
          3.854402542114258,
          4.249168395996094,
          3.5626277923583984,
          1.970697283744812,
          3.7032265663146973,
          4.169369220733643,
          3.481147050857544,
          3.4255259037017822,
          3.0524280071258545,
          3.352940797805786,
          3.8458571434020996,
          4.302882671356201,
          2.189626932144165,
          3.5851120948791504,
          3.575941562652588,
          4.2144598960876465,
          3.2106871604919434,
          3.3156254291534424,
          4.808958053588867,
          1.8798980712890625
         ],
         "yaxis": "y",
         "type": "scatter"
        },
        {
         "hovertemplate": "<b>%{hovertext}</b><br><br>Topics=deep.learning.mitotic.mammogram.mg.classification<br>x=%{x}<br>y=%{y}<extra></extra>",
         "hovertext": [
          "Multiparametric Magnetic Resonance Image Synthesis using Generative Adversarial Networks",
          "Semantic Segmentation of Brain Tumors in MRI Data Without any Labels",
          "Interactive Classification of Multi-Shell Diffusion MRI With Features From a Dual-Branch CNN Autoencoder",
          "A Guided Spatial Transformer Network for Histology Cell Differentiation",
          "Maximizing AUC with Deep Learning for Classification of Imbalanced Mammogram Datasets",
          "Mammogram Classification and Abnormality Detection from Nonlocal Labels using Deep Multiple Instance Neural Network"
         ],
         "legendgroup": "deep.learning.mitotic.mammogram.mg.classification",
         "marker": {
          "color": "#B6E880",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "deep.learning.mitotic.mammogram.mg.classification",
         "orientation": "v",
         "showlegend": true,
         "x": [
          5.301027297973633,
          5.1189374923706055,
          5.420026779174805,
          4.615950107574463,
          5.0057053565979,
          4.940236568450928
         ],
         "xaxis": "x",
         "y": [
          1.6709372997283936,
          1.583765983581543,
          1.7861008644104004,
          1.7340881824493408,
          1.5717023611068726,
          1.6056137084960938
         ],
         "yaxis": "y",
         "type": "scatter"
        },
        {
         "hovertemplate": "<b>%{hovertext}</b><br><br>Topics=motion.registration.lung.correction.mean.physiological<br>x=%{x}<br>y=%{y}<extra></extra>",
         "hovertext": [
          "Misalignment Correction in Open Cone-Beam CT",
          "Generation of a Mean Motion Model of the Lung Using 4D-CT Image Data",
          "Image Registration Methods for Patient-Specific Virtual Physiological Human Models",
          "Simulated Motion Artefact in Computed Tomography"
         ],
         "legendgroup": "motion.registration.lung.correction.mean.physiological",
         "marker": {
          "color": "#FF97FF",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "motion.registration.lung.correction.mean.physiological",
         "orientation": "v",
         "showlegend": true,
         "x": [
          2.092632532119751,
          1.8023443222045898,
          1.8113094568252563,
          1.8988211154937744
         ],
         "xaxis": "x",
         "y": [
          3.7350516319274902,
          3.680861473083496,
          3.9993717670440674,
          3.7407479286193848
         ],
         "yaxis": "y",
         "type": "scatter"
        },
        {
         "hovertemplate": "<b>%{hovertext}</b><br><br>Topics=vascular.vessel.blood.aneurysm.lumen.vessels<br>x=%{x}<br>y=%{y}<extra></extra>",
         "hovertext": [
          "Distance Field Visualization and 2D Abstraction of Vessel Tree Structures with on-the-fly Parameterization",
          "Reconstruction of Blood Vessels from Neck CT Datasets using Stable 3D Mass-Spring Models",
          "Automatic Animations to Analyze Blood Flow Data",
          "Visual Assessment of Vascular Torsion using Ellipse Fitting",
          "Combining Pseudo Chroma Depth Enhancement and Parameter Mapping for Vascular Surface Models",
          "Adapted Surface Visualization of Cerebral Aneurysms with Embedded Blood Flow Information",
          "Aneulysis - A System for Aneurysm Data Analysis",
          "Aortic Dissection Maps: Comprehensive Visualization of Aortic Dissections for Risk Assessment",
          "Semi-Immersive 3D Sketching of Vascular Structures for Medical Education",
          "Automatic Cutting and Flattening of Carotid Artery Geometries",
          "From Imprecise User Input to Precise Vessel Segmentations",
          "Robustness Evaluation of CFD Simulations to Mesh Deformation",
          "Shading Style Assessment for Vessel Wall and Lumen Visualization",
          "Efficient Globally Optimal Matching of Anatomical Trees of the Liver",
          "Parameterization and Feature Extraction for the Visualization of Tree-like Structures",
          "Concentric Circle Glyphs for Enhanced Depth-Judgment in Vascular Models",
          "Imaging the Vascular Network of the Human Spleen from Immunostained Serial Sections",
          "The Virtual Reality Flow Lens for Blood Flow Exploration",
          "Evolutionary Pathlines for Blood Flow Exploration in Cerebral Aneurysms",
          "Evaluation of Transfer Function Methods in Direct Volume Rendering of the Blood Vessel Lumen"
         ],
         "legendgroup": "vascular.vessel.blood.aneurysm.lumen.vessels",
         "marker": {
          "color": "#FECB52",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "vascular.vessel.blood.aneurysm.lumen.vessels",
         "orientation": "v",
         "showlegend": true,
         "x": [
          4.115127086639404,
          3.5604560375213623,
          3.206904649734497,
          3.8934707641601562,
          3.7311079502105713,
          3.3558759689331055,
          2.96069073677063,
          3.7009222507476807,
          3.639672040939331,
          3.874483585357666,
          3.7446155548095703,
          2.9706108570098877,
          3.690908432006836,
          3.924647569656372,
          4.171051025390625,
          3.49356746673584,
          3.7309839725494385,
          3.532240629196167,
          3.0743513107299805,
          3.2992186546325684
         ],
         "xaxis": "x",
         "y": [
          5.614485740661621,
          5.404460906982422,
          6.399383068084717,
          5.480358600616455,
          6.293880462646484,
          6.147075176239014,
          6.630121231079102,
          6.54652738571167,
          5.826741695404053,
          5.578829765319824,
          5.472723007202148,
          6.556217670440674,
          6.47234582901001,
          4.875585079193115,
          5.559123516082764,
          5.927253723144531,
          5.116188049316406,
          6.135775089263916,
          6.608036041259766,
          5.948219299316406
         ],
         "yaxis": "y",
         "type": "scatter"
        },
        {
         "hovertemplate": "<b>%{hovertext}</b><br><br>Topics=tumor.ius.pet.growth.roi.registration<br>x=%{x}<br>y=%{y}<extra></extra>",
         "hovertext": [
          "Application of Image Processing Functions for Brain Tumor Enhancement in Intraoperative Ultrasound Image Data",
          "Illustrative Multi-volume Rendering for PET/CT Scans",
          "On the Value of Multi-Volume Visualization for Preoperative Planning of Cerebral AVM Surgery",
          "Visualisation of PET data in the Fly Algorithm",
          "RegistrationShop: An Interactive 3D Medical Volume Registration System",
          "Towards Clinical Deployment of Automated Anatomical Regions-Of-Interest",
          "GPU Accelerated Normalized Mutual Information and B-Spline Transformation",
          "Visual Assessment of Growth Prediction in Brain Structures after Pediatric Radiotherapy",
          "High-Quality Multimodal Volume Visualization of Intracerebral Pathological Tissue",
          "Dynamic Visualisation of Orbital Fat Deformation using Anatomy-Guided Interaction"
         ],
         "legendgroup": "tumor.ius.pet.growth.roi.registration",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "tumor.ius.pet.growth.roi.registration",
         "orientation": "v",
         "showlegend": true,
         "x": [
          4.452044486999512,
          5.0610456466674805,
          4.582805633544922,
          4.869785785675049,
          4.8431525230407715,
          4.530712604522705,
          4.671106815338135,
          4.427118301391602,
          4.84854793548584,
          4.922366142272949
         ],
         "xaxis": "x",
         "y": [
          4.2352614402771,
          4.794524192810059,
          4.618265151977539,
          4.755444526672363,
          4.5885233879089355,
          4.687768459320068,
          4.339179992675781,
          4.110857963562012,
          4.458841800689697,
          4.524815082550049
         ],
         "yaxis": "y",
         "type": "scatter"
        },
        {
         "hovertemplate": "<b>%{hovertext}</b><br><br>Topics=connectivity.functional.neurons.networks.network.fu<br>x=%{x}<br>y=%{y}<extra></extra>",
         "hovertext": [
          "Synaptic Connectivity in Anatomically Realistic Neural Networks: Modeling and Visual Analysis",
          "Ontology-Based Visualization of Hierarchical Neuroanatomical Structures",
          "Visualizing and Exploring Dynamic Multichannel EEG Coherence Networks",
          "Graph Averaging as a Means to Compare Multichannel EEG Coherence Networks",
          "BrainCove: A Tool for Voxel-wise fMRI Brain Connectivity Visualization",
          "Iterative Exploration of Big Brain Network Data",
          "Visual Analysis of Evolution of EEG Coherence Networks employing Temporal Multidimensional Scaling",
          "Visual and Quantitative Analysis of Higher Order Arborization Overlaps for Neural Circuit Research",
          "Annotated Dendrograms for Neurons From the Larval Fruit Fly Brain",
          "Schematic Electrode Map for Navigation in Neuro Data Sets",
          "Visual Analysis of Integrated Resting State Functional Brain Connectivity and Anatomy"
         ],
         "legendgroup": "connectivity.functional.neurons.networks.network.fu",
         "marker": {
          "color": "#EF553B",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "connectivity.functional.neurons.networks.network.fu",
         "orientation": "v",
         "showlegend": true,
         "x": [
          9.635202407836914,
          9.04046630859375,
          9.067590713500977,
          9.055904388427734,
          9.248433113098145,
          9.390889167785645,
          9.169029235839844,
          9.745847702026367,
          9.837528228759766,
          9.07293701171875,
          9.190545082092285
         ],
         "xaxis": "x",
         "y": [
          4.236973285675049,
          4.721462726593018,
          4.225035190582275,
          4.211352348327637,
          4.034557342529297,
          4.123169422149658,
          4.101325035095215,
          4.332325458526611,
          4.420934200286865,
          4.416672229766846,
          4.087374687194824
         ],
         "yaxis": "y",
         "type": "scatter"
        },
        {
         "hovertemplate": "<b>%{hovertext}</b><br><br>Topics=ultrasound.hifu.mode.liver.tracing.ray<br>x=%{x}<br>y=%{y}<extra></extra>",
         "hovertext": [
          "Geometrical-Acoustics-based Ultrasound Image Simulation",
          "Deriving Anatomical Context from 4D Ultrasound",
          "HIFUpm: a Visual Environment to Plan and Monitor High Intensity Focused Ultrasound Treatments",
          "Monte-Carlo Ray-Tracing for Realistic Interactive Ultrasound Simulation",
          "Visibility-Driven Processing of Streaming Volume Data",
          "HIFUtk: Visual Analytics for High Intensity Focused Ultrasound Simulation",
          "Guided Visualization of Ultrasound Image Sequences",
          "Automatic Real-time Annotation of Important Landmarks in Ultrasound-Guided Femoral Nerve Blocks",
          "Combining B-Mode and Color Flow Vessel Segmentation for Registration of Hepatic CT and Ultrasound Volumes",
          "The Vitruvian Baby: Interactive Reformation of Fetal Ultrasound Data to a T-Position",
          "Lowest-Variance Streamlines for Filtering of 3D Ultrasound",
          "Visualization-Guided Evaluation of Simulated Minimally Invasive Cancer Treatment",
          "Ultrasound Decompression for Large Field-of-View Reconstructions",
          "Illustrated Ultrasound for Multimodal Data Interpretation of Liver Examinations"
         ],
         "legendgroup": "ultrasound.hifu.mode.liver.tracing.ray",
         "marker": {
          "color": "#00cc96",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "ultrasound.hifu.mode.liver.tracing.ray",
         "orientation": "v",
         "showlegend": true,
         "x": [
          6.122100830078125,
          2.070307970046997,
          6.4353132247924805,
          6.183332920074463,
          2.8430066108703613,
          6.490805149078369,
          2.187106132507324,
          1.9978992938995361,
          1.9100322723388672,
          2.119732618331909,
          2.8972482681274414,
          6.76882266998291,
          2.4780590534210205,
          1.9555509090423584
         ],
         "xaxis": "x",
         "y": [
          1.436800479888916,
          2.789285898208618,
          1.3594399690628052,
          1.41110360622406,
          2.7635035514831543,
          1.4156780242919922,
          2.366774320602417,
          2.744917631149292,
          2.749272346496582,
          2.3543362617492676,
          2.8653323650360107,
          1.5145460367202759,
          2.9167568683624268,
          2.514000177383423
         ],
         "yaxis": "y",
         "type": "scatter"
        },
        {
         "hovertemplate": "<b>%{hovertext}</b><br><br>Topics=evaluations.biomedical.communication.evaluation.practice.preferences<br>x=%{x}<br>y=%{y}<extra></extra>",
         "hovertext": [
          "A Critical Analysis of the Evaluation Practice in Medical Visualization",
          "An Exploration of Practice and Preferences for the Visual Communication of Biomedical Processes",
          "Automatic Generation of Web-Based User Studies to Evaluate Depth Perception in Vascular Surface Visualizations",
          "How to Evaluate Medical Visualizations on the Example of 3D Aneurysm Surfaces"
         ],
         "legendgroup": "evaluations.biomedical.communication.evaluation.practice.preferences",
         "marker": {
          "color": "#ab63fa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "evaluations.biomedical.communication.evaluation.practice.preferences",
         "orientation": "v",
         "showlegend": true,
         "x": [
          2.859095811843872,
          2.9717156887054443,
          2.98075532913208,
          3.0749669075012207
         ],
         "xaxis": "x",
         "y": [
          5.666492462158203,
          5.6923651695251465,
          5.828360557556152,
          5.877379417419434
         ],
         "yaxis": "y",
         "type": "scatter"
        },
        {
         "hovertemplate": "<b>%{hovertext}</b><br><br>Topics=flow.cardiac.pc.heart.4d.mri<br>x=%{x}<br>y=%{y}<extra></extra>",
         "hovertext": [
          "Visual Analysis of Regional Anomalies in Myocardial Motion",
          "2.5D Geometric Mapping of Aortic Blood Flow Data for Cohort Visualization",
          "Strategies for Generating Multi-Time Frame Localization of Cardiac MRI",
          "A Framework for Visual Comparison of 4D PC-MRI Aortic Blood Flow Data",
          "A Web-Based Tool for Cardiac Dyssynchrony Assessment on Ultrasound Data",
          "Interactive Visual Similarity Analysis of Measured and Simulated Multi-field Tubular Flow Ensembles",
          "A Survey of Cardiac 4D PC-MRI Data Processing",
          "Recent Advances in MRI and Ultrasound Perfusion Imaging",
          "Motion-moderated Transfer Function for Volume Rendering 4D CMR Data",
          "InkVis: A High-Particle-Count Approach for Visualization of Phase-Contrast Magnetic Resonance Imaging Data",
          "Spatio-temporal Visualization of Regional Myocardial Velocities",
          "A Framework for Fast Initial Exploration of PC-MRI Cardiac Flow",
          "Semi-Automatic Vessel Boundary Detection in Cardiac 4D PC-MRI Data Using FTLE fields",
          "Temporal Interpolation of 4D PC-MRI Blood-flow Measurements Using Bidirectional Physics-based Fluid Simulation",
          "Glyph-Based Visualization of Myocardial Perfusion Data and Enhancement with Contractility and Viability Information",
          "Computation and Visualization of Asynchronous Behavior of the Heart",
          "Robust Cardiac Function Assessment in 4D PC-MRI Data",
          "CT Late Enhancement Segmentation for the Combined Analysis of Coronary Arteries and Myocardial Viability",
          "Exploration of Interventricular Septum Motion in Multi-Cycle Cardiac MRI",
          "Coherence Maps for Blood Flow Exploration"
         ],
         "legendgroup": "flow.cardiac.pc.heart.4d.mri",
         "marker": {
          "color": "#FFA15A",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "flow.cardiac.pc.heart.4d.mri",
         "orientation": "v",
         "showlegend": true,
         "x": [
          4.669671058654785,
          3.589738368988037,
          3.5121471881866455,
          3.7888972759246826,
          4.913083076477051,
          3.7904462814331055,
          3.5362331867218018,
          4.021820545196533,
          3.650059461593628,
          4.007194519042969,
          4.623615741729736,
          3.920229911804199,
          3.4421820640563965,
          3.6616604328155518,
          4.071868419647217,
          4.885587692260742,
          3.653762102127075,
          3.9763846397399902,
          4.73019552230835,
          3.4849624633789062
         ],
         "xaxis": "x",
         "y": [
          9.173772811889648,
          9.210819244384766,
          9.150259017944336,
          9.428169250488281,
          9.242599487304688,
          9.488009452819824,
          9.189637184143066,
          9.00275993347168,
          9.282461166381836,
          9.327967643737793,
          9.078448295593262,
          9.165833473205566,
          9.472344398498535,
          9.40076732635498,
          8.972015380859375,
          9.252713203430176,
          9.131651878356934,
          8.865918159484863,
          9.135003089904785,
          9.546984672546387
         ],
         "yaxis": "y",
         "type": "scatter"
        },
        {
         "hovertemplate": "<b>%{hovertext}</b><br><br>Topics=valve.stress.implant.mitral.residual.bone<br>x=%{x}<br>y=%{y}<extra></extra>",
         "hovertext": [
          "Using Position-Based Dynamics for Simulating the Mitral Valve in a Decision Support System",
          "Projection Mapping for In-Situ Surgery Planning by the Example of DIEP Flap Breast Reconstruction",
          "Interactive Residual Stress Modeling for Soft Tissue Simulation",
          "VRIDAA: Virtual Reality Platform for Training and Planning Implantations of Occluder Devices in Left Atrial Appendages",
          "Computational Steering for Patient-Specific Implant Planning in Orthopedics"
         ],
         "legendgroup": "valve.stress.implant.mitral.residual.bone",
         "marker": {
          "color": "#19d3f3",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "valve.stress.implant.mitral.residual.bone",
         "orientation": "v",
         "showlegend": true,
         "x": [
          0.5959076881408691,
          0.7432489991188049,
          0.9978950023651123,
          0.7286272048950195,
          1.0789377689361572
         ],
         "xaxis": "x",
         "y": [
          4.303058624267578,
          3.368222713470459,
          4.285902500152588,
          3.479966640472412,
          4.244519233703613
         ],
         "yaxis": "y",
         "type": "scatter"
        },
        {
         "hovertemplate": "<b>%{hovertext}</b><br><br>Topics=fiber.tractography.crossing.tracts.diffusion.white<br>x=%{x}<br>y=%{y}<extra></extra>",
         "hovertext": [
          "The BundleExplorer: A Focus and Context Rendering Framework for Complex Fiber Distributions",
          "Progressive and Efficient Multi-Resolution Representations for Brain Tractograms",
          "Multi-fiber Estimation and Tractography for Diffusion MRI using mixture of Non-central Wishart Distributions",
          "Reducing Model Uncertainty in Crossing Fiber Tractography",
          "Visualizing White Matter Fiber Tracts with Optimally Fitted Curved Dissection Surfaces",
          "Fiber Stipples for Crossing Tracts in Probabilistic Tractography",
          "Accelerated Diffusion Operators for Enhancing DW-MRI"
         ],
         "legendgroup": "fiber.tractography.crossing.tracts.diffusion.white",
         "marker": {
          "color": "#FF6692",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "fiber.tractography.crossing.tracts.diffusion.white",
         "orientation": "v",
         "showlegend": true,
         "x": [
          6.164465427398682,
          6.216649532318115,
          6.504331588745117,
          6.4561686515808105,
          6.247125148773193,
          6.279637336730957,
          6.563508987426758
         ],
         "xaxis": "x",
         "y": [
          4.476739406585693,
          4.41409969329834,
          4.035645008087158,
          4.095235824584961,
          4.325950622558594,
          4.288823127746582,
          3.914127826690674
         ],
         "yaxis": "y",
         "type": "scatter"
        },
        {
         "hoverlabel": {
          "bgcolor": "#ffffff",
          "bordercolor": "#BDBDBD",
          "font": {
           "color": "#141414",
           "family": "Calibri",
           "size": 12
          }
         },
         "hovertemplate": "<b>%{hovertext}<br></b><br>0=%{x}<br>1=%{y}",
         "hovertext": [
          "Pelvis Runner: Visualizing Pelvic Organ Variability in a Cohort of Radiotherapy Patients",
          "Information-based Transfer Functions for Multimodal Visualization",
          "Feasibility Study For Automatic Bird Tracking and Visualization from Time-Dependent Marine Radar Imagery",
          "CT-Based Navigation Guidance for Liver Tumor Ablation",
          "Design Considerations for Immersive Analytics of Bird Movements Obtained by Miniaturised GPS Sensors",
          "Sline: Seamless Line Illustration for Interactive Biomedical Visualization",
          "Estimation of Muscle Activity in One-Leg Stance from 3D Surface Deformation",
          "An Integrated Platform for Dynamic Cardiac Simulation and Image Processing: Application to Personalised Tetralogy of Fallot Simulation",
          "Medical Animations: A Survey and a Research Agenda",
          "Automatic Hepatocyte Quantification from Histological Images: Comparing Pre-smoothing filters",
          "Constrained Labeling of 2D Slice Data for Reading Images in Radiology",
          "Survey of Labeling Techniques in Medical Visualizations",
          "Tractography in Context: Multimodal Visualization of Probabilistic Tractograms in Anatomical Context",
          "A Web-based Application for the Visual Exploration of Colon Morphology Data",
          "Vologram: An Educational Holographic Sculpture for Volumetric Medical Data Physicalization",
          "The iCoCooN: Integration of Cobweb Charts with Parallel Coordinates for Visual Analysis of DCE-MRI Modeling Variations",
          "Personalized X-ray Reconstruction of the Proximal Femur via a New Control Point-based 2D-3D Registration and Residual Complexity Minimization",
          "Graxels: Information Rich Primitives for the Visualization of Time-Dependent Spatial Data",
          "Focus + Context Rendering of Structured Biomedical Data",
          "Interactive Real Time Simulation of Cardiac Radio-Frequency Ablation",
          "Illustrative PET/CT Visualisation of SIRT-Treated Lung Metastases",
          "Interactive Visualization of Muscle Activity During Limb Movements: Towards Enhanced Anatomy Learning",
          "Feature Exploration using Local Frequency Distributions in Computed Tomography Data",
          "Importance-Driven Structure Categorization for 3D Surgery Planning",
          "Interactive Position-dependent Customization of Transfer Function Classification Parameters in Volume Rendering",
          "Interactive Labeling of Toponome Data"
         ],
         "marker": {
          "color": "#BDBDBD"
         },
         "mode": "markers",
         "name": "Selected",
         "showlegend": false,
         "x": [
          6.848759174346924,
          5.211584091186523,
          4.70186710357666,
          1.534815788269043,
          4.56682014465332,
          5.74480676651001,
          1.3579542636871338,
          0.6152433156967163,
          1.0076299905776978,
          4.478983402252197,
          6.092660427093506,
          6.074634075164795,
          5.834123134613037,
          3.9063572883605957,
          1.0430923700332642,
          7.1601433753967285,
          2.2156052589416504,
          5.7240800857543945,
          6.076847553253174,
          0.5793965458869934,
          5.262200355529785,
          1.0082603693008423,
          5.730375289916992,
          6.099911212921143,
          5.159655570983887,
          9.93909740447998
         ],
         "y": [
          1.5508618354797363,
          5.694760322570801,
          7.084474563598633,
          2.812906265258789,
          6.985806941986084,
          5.304762840270996,
          3.8656165599823,
          4.448028087615967,
          3.4530465602874756,
          1.8187189102172852,
          5.498110771179199,
          5.50588846206665,
          4.580630779266357,
          1.8577338457107544,
          3.2064671516418457,
          1.736873984336853,
          4.111143589019775,
          6.064004421234131,
          5.731310844421387,
          4.407580375671387,
          4.9625773429870605,
          3.715463876724243,
          6.088668346405029,
          5.658929824829102,
          5.83262300491333,
          5.841947078704834
         ],
         "type": "scatter"
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0.0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1.0,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0.0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1.0,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0.0,
          1.0
         ],
         "title": {
          "text": "x"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0.0,
          1.0
         ],
         "title": {
          "text": "y"
         }
        },
        "legend": {
         "title": {
          "text": "Topics"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        }
       },
       "config": {
        "plotlyServerURL": "https://plot.ly"
       }
      },
      "text/html": "<div>                            <div id=\"0ed791fd-be4c-4702-a621-5a85632572f7\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"0ed791fd-be4c-4702-a621-5a85632572f7\")) {                    Plotly.newPlot(                        \"0ed791fd-be4c-4702-a621-5a85632572f7\",                        [{\"hovertemplate\":\"<b>%{hovertext}</b><br><br>Topics=molecular.protein.proteins.molecule.molecules.tunnels<br>x=%{x}<br>y=%{y}<extra></extra>\",\"hovertext\":[\"Interactive Exploded Views for Molecular Structures\",\"Atomistic Visualization of Mesoscopic Whole-Cell Simulations\",\"Watergate: Visual Exploration of Water Trajectories in Protein Dynamics\",\"cellVIEW: a Tool for Illustrative and Multi-Scale Rendering of Large Biomolecular Datasets\",\"Visual Analysis and Comparison of Multiple Sequence Alignments\",\"Membrane Mapping: Combining Mesoscopic and Molecular Cell Visualization\",\"Analyzing Protein Similarity by Clustering Molecular Surface Maps\",\"A Haptic Rendering Algorithm for Molecular Interaction\",\"Real-Time Visualization of 3D Amyloid-Beta Fibrils from 2D Cryo-EM Density Maps\",\"Unfolding and Interactive Exploration of Protein Tunnels and their Dynamics\",\"DockVis: Visual Analysis of Molecular Docking Data\",\"Protein Tunnel Reprojection for Physico-Chemical Property Analysis\",\"Interactive CPU-based Ray Tracing of Solvent Excluded Surfaces\",\"Visualization and Exploration of 3D Toponome Data\",\"Computation of More Channels in Protein Molecules\",\"Visual Analysis of Bipartite Biological Networks\",\"Illustrative Transitions in Molecular Visualization via Forward and Inverse Abstraction Transform\",\"Hybrid Visualization of Protein-Lipid and Protein-Protein Interaction\",\"Molecular Sombreros: Abstract Visualization of Binding Sites within Proteins\",\"Chameleon - Dynamic Color Mapping for Multi-Scale Structural Biology Models\",\"Instant Visualization of Secondary Structures of Molecular Models\",\"Visualizing Movements of Protein Tunnels in Molecular Dynamics Simulations\",\"FoldSynth: Interactive 2D/3D Visualisation Platform for Molecular Strands\",\"FluoroSim: A Visual Problem-Solving Environment for Fluorescence Microscopy\",\"Improving Perception of Molecular Surface Visualizations by Incorporating Translucency Effects\",\"Real-Time Dense Nucleus Selection from Confocal Data\",\"Semantic Screen-Space Occlusion for Multiscale Molecular Visualization\"],\"legendgroup\":\"molecular.protein.proteins.molecule.molecules.tunnels\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"molecular.protein.proteins.molecule.molecules.tunnels\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[11.353458404541016,11.112112998962402,11.513835906982422,11.24240779876709,11.486777305603027,10.96341323852539,11.436065673828125,11.427106857299805,11.040488243103027,11.525171279907227,11.570666313171387,11.77976131439209,11.007094383239746,10.274176597595215,11.808584213256836,11.275152206420898,10.982041358947754,11.378890991210938,11.496362686157227,10.44150161743164,11.285989761352539,11.752182960510254,11.324108123779297,10.824968338012695,10.879570007324219,10.270232200622559,10.431352615356445],\"xaxis\":\"x\",\"y\":[6.531891345977783,5.932096004486084,6.844592094421387,6.18428897857666,7.280216693878174,5.841034412384033,7.2732768058776855,6.417327880859375,5.786619186401367,6.956653594970703,7.149440765380859,7.043140888214111,5.929601669311523,6.059593677520752,7.032642364501953,6.9299702644348145,6.569153308868408,6.810847282409668,7.240987777709961,6.238524913787842,6.2454633712768555,6.835847854614258,6.50663948059082,5.598160743713379,5.951852798461914,4.882491588592529,6.164299011230469],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"<b>%{hovertext}</b><br><br>Topics=projection.textures.distortions.projections.wdt.solid<br>x=%{x}<br>y=%{y}<extra></extra>\",\"hovertext\":[\"Layer-Aware iOCT Volume Rendering for Retinal Surgery\",\"Anatomical Volume Visualization with Weighted Distance Fields\",\"VisualFlatter - Visual Analysis of Distortions in the Projection of Biomedical Structures\",\"Model-based Solid Texture Synthesis for Anatomic Volume Illustration\",\"Volume Visualization Using Principal Component Analysis\"],\"legendgroup\":\"projection.textures.distortions.projections.wdt.solid\",\"marker\":{\"color\":\"#EF553B\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"projection.textures.distortions.projections.wdt.solid\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[4.5864739418029785,4.885083198547363,5.43342924118042,4.297755241394043,4.932013034820557],\"xaxis\":\"x\",\"y\":[6.019912242889404,5.6325578689575195,5.255282402038574,5.578217029571533,5.768516540527344],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"<b>%{hovertext}</b><br><br>Topics=analytics.pathologists.pathology.thermal.digital.diagnostic<br>x=%{x}<br>y=%{y}<extra></extra>\",\"hovertext\":[\"Introducing CNN-Based Mouse Grim Scale Analysis for Fully Automated Image-Based Assessment of Distress in Laboratory Mice\",\"PerSleep: A Visual Analytics Approach for Performance Assessment of Sleep Staging Models\",\"PATHONE: From one Thousand Patients to one Cell\",\"Visual Analytics in Histopathology Diagnostics: a Protocol-Based Approach\",\"Discovering Medical Knowledge Using Visual Analytics\",\"preha: Establishing Precision Rehabilitation with Visual Analytics\",\"Visual Analytics in Digital Pathology: Challenges and Opportunities\",\"Visual Analytics of Missing Data in Epidemiological Cohort Studies\",\"SWiFT Seeing the Wood From the Trees: helping people make sense of their health data\",\"Visual Analysis of Multivariate Intensive Care Surveillance Data\",\"Inlier Detection in Thermal Sensitive Images\",\"GLANCE: Visual Analytics for Monitoring Glaucoma Progression\",\"A Visual Analytics Approach for Patient Stratification and Biomarker Discovery\",\"Multiple Scale Visualization of Electronic Health Records to Support Finding Medical Narratives\"],\"legendgroup\":\"analytics.pathologists.pathology.thermal.digital.diagnostic\",\"marker\":{\"color\":\"#00cc96\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"analytics.pathologists.pathology.thermal.digital.diagnostic\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[8.095111846923828,8.143762588500977,8.337512969970703,8.36275863647461,8.238160133361816,8.37795352935791,8.253508567810059,8.03293514251709,8.373919486999512,7.923770427703857,7.508171081542969,8.228536605834961,8.038070678710938,8.361105918884277],\"xaxis\":\"x\",\"y\":[1.2424747943878174,1.4833321571350098,1.033328890800476,1.1142884492874146,1.5583330392837524,1.7313401699066162,1.311887264251709,1.6081548929214478,1.7053402662277222,1.5169579982757568,1.4046655893325806,1.3522526025772095,1.5544962882995605,1.7230041027069092],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"<b>%{hovertext}</b><br><br>Topics=reality.display.xr.vr.ar.simulator<br>x=%{x}<br>y=%{y}<extra></extra>\",\"hovertext\":[\"VR Acrophobia Treatment - Development of Customizable Acrophobia Inducing Scenarios\",\"Student and Teacher Meet in a Shared Virtual Reality: A one-on-one Tutoring System for Anatomy Education\",\"Real-Time Guidance and Anatomical Information by Image Projection onto Patients\",\"Exploration of 3D Medical Image Data for Interventional Radiology using Myoelectric Gesture Control\",\"Visual Navigation Support for Liver Applicator Placement using Interactive Map Displays\",\"Haptics-based Modelling of Pigmented Skin Lesions\",\"A Prototype Holographic Augmented Reality Interface for Image-Guided Prostate Cancer Interventions\",\"An Endoscope Interface for Immersive Virtual Reality\",\"Simulation-based Ultrasound Training Supported by Annotations, Haptics and Linked Multimodal Views\",\"A Comparative User Study of a 2D and an Autostereoscopic 3D Display for a Tympanoplastic Surgery\",\"ICG based Augmented-Reality-System for Sentinel Lymph Node Biopsy\",\"The Role of Depth Perception in XR from a Neuroscience Perspective: A Primer and Survey\",\"QuantiScale: A Study in Redesigning Interactions for Multi-Touch\",\"Learning Hand Anatomy with Sense of Embodiment\",\"A Haptics-enabled Simulator for Transperineal Ultrasound-Guided Biopsy\",\"Challenges and Technologies for Low Cost Wheelchair Simulation\",\"AR-Assisted Craniotomy Planning for Tumour Resection\"],\"legendgroup\":\"reality.display.xr.vr.ar.simulator\",\"marker\":{\"color\":\"#ab63fa\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"reality.display.xr.vr.ar.simulator\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[-0.15456660091876984,0.055098604410886765,0.40030503273010254,0.6294278502464294,0.8374735116958618,0.41181501746177673,0.28528454899787903,0.1146928071975708,0.742165744304657,0.7479794025421143,0.42694607377052307,0.8408085107803345,0.628268837928772,-0.031119532883167267,0.3179212808609009,-0.06460881233215332,0.5496626496315002],\"xaxis\":\"x\",\"y\":[3.3537180423736572,3.2239298820495605,3.267148017883301,2.612415313720703,3.315467119216919,2.5433151721954346,2.880283832550049,3.1742827892303467,2.684331178665161,2.874549388885498,3.0263850688934326,2.942121744155884,2.6263747215270996,3.395559787750244,2.621673583984375,3.3224847316741943,3.0001699924468994],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"<b>%{hovertext}</b><br><br>Topics=tensor.diffusion.maze.uncertainty.formation.groups<br>x=%{x}<br>y=%{y}<extra></extra>\",\"hovertext\":[\"Visual Exploratory Analysis for Multiple T-Maze Studies\",\"Interactive Formation of Statistical Hypotheses in Diffusion Tensor Imaging\",\"Comparative Visualization for Diffusion Tensor Imaging Group Study at Multiple Levels of Detail\",\"Interactive Multimodal Imaging Visualization for Multiple Sclerosis Lesion Analysis\",\"SpectraMosaic: An Exploratory Tool for the Interactive Visual Analysis of Magnetic Resonance Spectroscopy Data\",\"A Survey on Visualizing Magnetic Resonance Spectroscopy Data\",\"Deriving and Visualizing Uncertainty in Kinetic PET Modeling\",\"MedUse: A Visual Analysis Tool for Medication Use Data in the ABCD Study\",\"A Visual Environment for Hypothesis Formation and Reasoning in Studies with fMRI and Multivariate Clinical Data\"],\"legendgroup\":\"tensor.diffusion.maze.uncertainty.formation.groups\",\"marker\":{\"color\":\"#FFA15A\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"tensor.diffusion.maze.uncertainty.formation.groups\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[7.230952262878418,7.167733669281006,7.101341247558594,7.053091526031494,7.547104835510254,7.441543102264404,7.314080715179443,7.699601173400879,7.645349979400635],\"xaxis\":\"x\",\"y\":[3.013587474822998,2.8900609016418457,2.903024673461914,2.7751667499542236,2.0227277278900146,1.8272175788879395,1.8435899019241333,2.050260305404663,2.126694440841675],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"<b>%{hovertext}</b><br><br>Topics=cta.arteries.artery.cerebral.vessels.cow<br>x=%{x}<br>y=%{y}<extra></extra>\",\"hovertext\":[\"CoWRadar: Visual Quantification of the Circle of Willis in Stroke Patients\",\"A New Vessel Enhancement Transform on Retinal Blood Vessels Segmentation\",\"Histology-Based Evaluation of Optical Coherence Tomographic Characteristics of the Cerebral Artery Wall via Virtual Inflating\",\"VirtualDSA++: Automated Segmentation, Vessel Labeling, Occlusion Detection and Graph Search on CT-Angiography Data\",\"Automatic Thrombus Detection in Non-enhanced Computed Tomography Images in Patients With Acute Ischemic Stroke\",\"A Two-Level Cascade Classification Algorithm for Real-Time Bifurcation Detection in CTA Images of Blood Vessels\",\"Automated Slice-Based Artery Identification in Various Field-of-View CTA Scans\"],\"legendgroup\":\"cta.arteries.artery.cerebral.vessels.cow\",\"marker\":{\"color\":\"#19d3f3\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"cta.arteries.artery.cerebral.vessels.cow\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[1.857552170753479,1.5877735614776611,2.1502737998962402,1.6897293329238892,1.5963013172149658,1.600284457206726,1.6439483165740967],\"xaxis\":\"x\",\"y\":[5.731562614440918,5.792247772216797,5.880738258361816,5.7284111976623535,5.735196113586426,5.771534442901611,5.764368534088135],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"<b>%{hovertext}</b><br><br>Topics=segmentation.shape.surface.mesh.uncertainty.segmentations<br>x=%{x}<br>y=%{y}<extra></extra>\",\"hovertext\":[\"Automatic Segmentation of the Pelvic Bones from CT Data Based on a Statistical Shape Model\",\"Estimation of the Midsagittal Plane for Sideness Determination of Malignant Structures of Head and Neck\",\"A Multilinear Model for Bidirectional Craniofacial Reconstruction\",\"Sketch-based Image-independent Editing of 3D Tumor Segmentations using Variational Interpolation\",\"Uncertainty-aware Brain Lesion Visualization\",\"Bone Fracture and Lesion Assessment using Shape-Adaptive Unfolding\",\"Polar Space Based Shape Averaging for Star-shaped Biological Objects\",\"Visually Guided Mesh Smoothing for Medical Applications\",\"Robust Classification and Analysis of Anatomical Surfaces Using 3D Skeletons\",\"Fast and Smooth Interactive Segmentation of Medical Images Using Variational Interpolation\",\"A Statistical Method for Surface Detection\",\"A General Approach to Model Biomedical Data from 3D Unorganised Point Clouds with Medial Scaffolds\",\"Visual Analysis of Medical Image Segmentation Feature Space for Interactive Supervised Classification\",\"Colonic Content Assessment from MRI Imaging Using a Semi-automatic Approach\",\"Evaluation of Hippocampal Segmentation Methods for Healthy and Pathological Subjects\",\"Fully Automatic Skull-Stripping in 3D Time-of-Flight MRA Image Sequences\",\"Extracting and Visualizing Uncertainties in Segmentations from 3D Medical Data\",\"Uncertainty-aware Ensemble of Classifiers for Segmenting Brain MRI Data\",\"Impact of Physical Noise Modeling on Image Segmentation in Echocardiography\",\"Uncertainty Estimation and Visualization for Multi-modal Image Segmentation\",\"MRI Hip Joint Segmentation: A Locally Bhattacharyya Weighted Hybrid 3D Level Set Approach\",\"Global and Local Mesh Morphing for Complex Biological Objects from \\u00b5CT Data\",\"Surface Curvature Line Clustering for Polyp Detection in CT Colonography\",\"Staircase-Aware Smoothing of Medical Surface Meshes\",\"Visual Analytics for the Exploration and Assessment of Segmentation Errors\",\"Parametric-based Reconstruction Of 3D Mesh Models; Towards the Generation of a Parametric Human Foot Biomodel\",\"Uncertainty-Guided Semi-Automated Editing of CNN-based Retinal Layer Segmentations in Optical Coherence Tomography\",\"UI-Net: Interactive Artificial Neural Networks for Iterative Image Segmentation Based on a User Model\",\"A Feasibility Study on Automated Protein Aggregate Characterization Utilizing a Hybrid Classification Model\",\"InShaDe: Invariant Shape Descriptors for Visual Analysis of Histology 2D Cellular and Nuclear Shapes\"],\"legendgroup\":\"segmentation.shape.surface.mesh.uncertainty.segmentations\",\"marker\":{\"color\":\"#FF6692\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"segmentation.shape.surface.mesh.uncertainty.segmentations\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[4.136600971221924,4.257655620574951,2.9680378437042236,3.6068575382232666,4.713891983032227,4.15390682220459,4.1333746910095215,3.6982662677764893,3.191981315612793,3.709463596343994,3.5820164680480957,2.879034996032715,5.031764030456543,4.054015159606934,4.246856689453125,3.8068621158599854,3.869990110397339,4.444282531738281,3.168189764022827,4.596737861633301,3.634754180908203,2.77421498298645,4.210100173950195,3.712059497833252,4.969600200653076,2.3823115825653076,5.183164119720459,5.148957252502441,10.214855194091797,4.474748611450195],\"xaxis\":\"x\",\"y\":[2.449707269668579,3.860448122024536,4.140015125274658,3.670257806777954,3.399951457977295,2.6794986724853516,3.2411012649536133,3.553194999694824,4.005304336547852,3.6797280311584473,3.854402542114258,4.249168395996094,3.5626277923583984,1.970697283744812,3.7032265663146973,4.169369220733643,3.481147050857544,3.4255259037017822,3.0524280071258545,3.352940797805786,3.8458571434020996,4.302882671356201,2.189626932144165,3.5851120948791504,3.575941562652588,4.2144598960876465,3.2106871604919434,3.3156254291534424,4.808958053588867,1.8798980712890625],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"<b>%{hovertext}</b><br><br>Topics=deep.learning.mitotic.mammogram.mg.classification<br>x=%{x}<br>y=%{y}<extra></extra>\",\"hovertext\":[\"Multiparametric Magnetic Resonance Image Synthesis using Generative Adversarial Networks\",\"Semantic Segmentation of Brain Tumors in MRI Data Without any Labels\",\"Interactive Classification of Multi-Shell Diffusion MRI With Features From a Dual-Branch CNN Autoencoder\",\"A Guided Spatial Transformer Network for Histology Cell Differentiation\",\"Maximizing AUC with Deep Learning for Classification of Imbalanced Mammogram Datasets\",\"Mammogram Classification and Abnormality Detection from Nonlocal Labels using Deep Multiple Instance Neural Network\"],\"legendgroup\":\"deep.learning.mitotic.mammogram.mg.classification\",\"marker\":{\"color\":\"#B6E880\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"deep.learning.mitotic.mammogram.mg.classification\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[5.301027297973633,5.1189374923706055,5.420026779174805,4.615950107574463,5.0057053565979,4.940236568450928],\"xaxis\":\"x\",\"y\":[1.6709372997283936,1.583765983581543,1.7861008644104004,1.7340881824493408,1.5717023611068726,1.6056137084960938],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"<b>%{hovertext}</b><br><br>Topics=motion.registration.lung.correction.mean.physiological<br>x=%{x}<br>y=%{y}<extra></extra>\",\"hovertext\":[\"Misalignment Correction in Open Cone-Beam CT\",\"Generation of a Mean Motion Model of the Lung Using 4D-CT Image Data\",\"Image Registration Methods for Patient-Specific Virtual Physiological Human Models\",\"Simulated Motion Artefact in Computed Tomography\"],\"legendgroup\":\"motion.registration.lung.correction.mean.physiological\",\"marker\":{\"color\":\"#FF97FF\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"motion.registration.lung.correction.mean.physiological\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[2.092632532119751,1.8023443222045898,1.8113094568252563,1.8988211154937744],\"xaxis\":\"x\",\"y\":[3.7350516319274902,3.680861473083496,3.9993717670440674,3.7407479286193848],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"<b>%{hovertext}</b><br><br>Topics=vascular.vessel.blood.aneurysm.lumen.vessels<br>x=%{x}<br>y=%{y}<extra></extra>\",\"hovertext\":[\"Distance Field Visualization and 2D Abstraction of Vessel Tree Structures with on-the-fly Parameterization\",\"Reconstruction of Blood Vessels from Neck CT Datasets using Stable 3D Mass-Spring Models\",\"Automatic Animations to Analyze Blood Flow Data\",\"Visual Assessment of Vascular Torsion using Ellipse Fitting\",\"Combining Pseudo Chroma Depth Enhancement and Parameter Mapping for Vascular Surface Models\",\"Adapted Surface Visualization of Cerebral Aneurysms with Embedded Blood Flow Information\",\"Aneulysis - A System for Aneurysm Data Analysis\",\"Aortic Dissection Maps: Comprehensive Visualization of Aortic Dissections for Risk Assessment\",\"Semi-Immersive 3D Sketching of Vascular Structures for Medical Education\",\"Automatic Cutting and Flattening of Carotid Artery Geometries\",\"From Imprecise User Input to Precise Vessel Segmentations\",\"Robustness Evaluation of CFD Simulations to Mesh Deformation\",\"Shading Style Assessment for Vessel Wall and Lumen Visualization\",\"Efficient Globally Optimal Matching of Anatomical Trees of the Liver\",\"Parameterization and Feature Extraction for the Visualization of Tree-like Structures\",\"Concentric Circle Glyphs for Enhanced Depth-Judgment in Vascular Models\",\"Imaging the Vascular Network of the Human Spleen from Immunostained Serial Sections\",\"The Virtual Reality Flow Lens for Blood Flow Exploration\",\"Evolutionary Pathlines for Blood Flow Exploration in Cerebral Aneurysms\",\"Evaluation of Transfer Function Methods in Direct Volume Rendering of the Blood Vessel Lumen\"],\"legendgroup\":\"vascular.vessel.blood.aneurysm.lumen.vessels\",\"marker\":{\"color\":\"#FECB52\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"vascular.vessel.blood.aneurysm.lumen.vessels\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[4.115127086639404,3.5604560375213623,3.206904649734497,3.8934707641601562,3.7311079502105713,3.3558759689331055,2.96069073677063,3.7009222507476807,3.639672040939331,3.874483585357666,3.7446155548095703,2.9706108570098877,3.690908432006836,3.924647569656372,4.171051025390625,3.49356746673584,3.7309839725494385,3.532240629196167,3.0743513107299805,3.2992186546325684],\"xaxis\":\"x\",\"y\":[5.614485740661621,5.404460906982422,6.399383068084717,5.480358600616455,6.293880462646484,6.147075176239014,6.630121231079102,6.54652738571167,5.826741695404053,5.578829765319824,5.472723007202148,6.556217670440674,6.47234582901001,4.875585079193115,5.559123516082764,5.927253723144531,5.116188049316406,6.135775089263916,6.608036041259766,5.948219299316406],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"<b>%{hovertext}</b><br><br>Topics=tumor.ius.pet.growth.roi.registration<br>x=%{x}<br>y=%{y}<extra></extra>\",\"hovertext\":[\"Application of Image Processing Functions for Brain Tumor Enhancement in Intraoperative Ultrasound Image Data\",\"Illustrative Multi-volume Rendering for PET/CT Scans\",\"On the Value of Multi-Volume Visualization for Preoperative Planning of Cerebral AVM Surgery\",\"Visualisation of PET data in the Fly Algorithm\",\"RegistrationShop: An Interactive 3D Medical Volume Registration System\",\"Towards Clinical Deployment of Automated Anatomical Regions-Of-Interest\",\"GPU Accelerated Normalized Mutual Information and B-Spline Transformation\",\"Visual Assessment of Growth Prediction in Brain Structures after Pediatric Radiotherapy\",\"High-Quality Multimodal Volume Visualization of Intracerebral Pathological Tissue\",\"Dynamic Visualisation of Orbital Fat Deformation using Anatomy-Guided Interaction\"],\"legendgroup\":\"tumor.ius.pet.growth.roi.registration\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"tumor.ius.pet.growth.roi.registration\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[4.452044486999512,5.0610456466674805,4.582805633544922,4.869785785675049,4.8431525230407715,4.530712604522705,4.671106815338135,4.427118301391602,4.84854793548584,4.922366142272949],\"xaxis\":\"x\",\"y\":[4.2352614402771,4.794524192810059,4.618265151977539,4.755444526672363,4.5885233879089355,4.687768459320068,4.339179992675781,4.110857963562012,4.458841800689697,4.524815082550049],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"<b>%{hovertext}</b><br><br>Topics=connectivity.functional.neurons.networks.network.fu<br>x=%{x}<br>y=%{y}<extra></extra>\",\"hovertext\":[\"Synaptic Connectivity in Anatomically Realistic Neural Networks: Modeling and Visual Analysis\",\"Ontology-Based Visualization of Hierarchical Neuroanatomical Structures\",\"Visualizing and Exploring Dynamic Multichannel EEG Coherence Networks\",\"Graph Averaging as a Means to Compare Multichannel EEG Coherence Networks\",\"BrainCove: A Tool for Voxel-wise fMRI Brain Connectivity Visualization\",\"Iterative Exploration of Big Brain Network Data\",\"Visual Analysis of Evolution of EEG Coherence Networks employing Temporal Multidimensional Scaling\",\"Visual and Quantitative Analysis of Higher Order Arborization Overlaps for Neural Circuit Research\",\"Annotated Dendrograms for Neurons From the Larval Fruit Fly Brain\",\"Schematic Electrode Map for Navigation in Neuro Data Sets\",\"Visual Analysis of Integrated Resting State Functional Brain Connectivity and Anatomy\"],\"legendgroup\":\"connectivity.functional.neurons.networks.network.fu\",\"marker\":{\"color\":\"#EF553B\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"connectivity.functional.neurons.networks.network.fu\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[9.635202407836914,9.04046630859375,9.067590713500977,9.055904388427734,9.248433113098145,9.390889167785645,9.169029235839844,9.745847702026367,9.837528228759766,9.07293701171875,9.190545082092285],\"xaxis\":\"x\",\"y\":[4.236973285675049,4.721462726593018,4.225035190582275,4.211352348327637,4.034557342529297,4.123169422149658,4.101325035095215,4.332325458526611,4.420934200286865,4.416672229766846,4.087374687194824],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"<b>%{hovertext}</b><br><br>Topics=ultrasound.hifu.mode.liver.tracing.ray<br>x=%{x}<br>y=%{y}<extra></extra>\",\"hovertext\":[\"Geometrical-Acoustics-based Ultrasound Image Simulation\",\"Deriving Anatomical Context from 4D Ultrasound\",\"HIFUpm: a Visual Environment to Plan and Monitor High Intensity Focused Ultrasound Treatments\",\"Monte-Carlo Ray-Tracing for Realistic Interactive Ultrasound Simulation\",\"Visibility-Driven Processing of Streaming Volume Data\",\"HIFUtk: Visual Analytics for High Intensity Focused Ultrasound Simulation\",\"Guided Visualization of Ultrasound Image Sequences\",\"Automatic Real-time Annotation of Important Landmarks in Ultrasound-Guided Femoral Nerve Blocks\",\"Combining B-Mode and Color Flow Vessel Segmentation for Registration of Hepatic CT and Ultrasound Volumes\",\"The Vitruvian Baby: Interactive Reformation of Fetal Ultrasound Data to a T-Position\",\"Lowest-Variance Streamlines for Filtering of 3D Ultrasound\",\"Visualization-Guided Evaluation of Simulated Minimally Invasive Cancer Treatment\",\"Ultrasound Decompression for Large Field-of-View Reconstructions\",\"Illustrated Ultrasound for Multimodal Data Interpretation of Liver Examinations\"],\"legendgroup\":\"ultrasound.hifu.mode.liver.tracing.ray\",\"marker\":{\"color\":\"#00cc96\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"ultrasound.hifu.mode.liver.tracing.ray\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[6.122100830078125,2.070307970046997,6.4353132247924805,6.183332920074463,2.8430066108703613,6.490805149078369,2.187106132507324,1.9978992938995361,1.9100322723388672,2.119732618331909,2.8972482681274414,6.76882266998291,2.4780590534210205,1.9555509090423584],\"xaxis\":\"x\",\"y\":[1.436800479888916,2.789285898208618,1.3594399690628052,1.41110360622406,2.7635035514831543,1.4156780242919922,2.366774320602417,2.744917631149292,2.749272346496582,2.3543362617492676,2.8653323650360107,1.5145460367202759,2.9167568683624268,2.514000177383423],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"<b>%{hovertext}</b><br><br>Topics=evaluations.biomedical.communication.evaluation.practice.preferences<br>x=%{x}<br>y=%{y}<extra></extra>\",\"hovertext\":[\"A Critical Analysis of the Evaluation Practice in Medical Visualization\",\"An Exploration of Practice and Preferences for the Visual Communication of Biomedical Processes\",\"Automatic Generation of Web-Based User Studies to Evaluate Depth Perception in Vascular Surface Visualizations\",\"How to Evaluate Medical Visualizations on the Example of 3D Aneurysm Surfaces\"],\"legendgroup\":\"evaluations.biomedical.communication.evaluation.practice.preferences\",\"marker\":{\"color\":\"#ab63fa\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"evaluations.biomedical.communication.evaluation.practice.preferences\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[2.859095811843872,2.9717156887054443,2.98075532913208,3.0749669075012207],\"xaxis\":\"x\",\"y\":[5.666492462158203,5.6923651695251465,5.828360557556152,5.877379417419434],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"<b>%{hovertext}</b><br><br>Topics=flow.cardiac.pc.heart.4d.mri<br>x=%{x}<br>y=%{y}<extra></extra>\",\"hovertext\":[\"Visual Analysis of Regional Anomalies in Myocardial Motion\",\"2.5D Geometric Mapping of Aortic Blood Flow Data for Cohort Visualization\",\"Strategies for Generating Multi-Time Frame Localization of Cardiac MRI\",\"A Framework for Visual Comparison of 4D PC-MRI Aortic Blood Flow Data\",\"A Web-Based Tool for Cardiac Dyssynchrony Assessment on Ultrasound Data\",\"Interactive Visual Similarity Analysis of Measured and Simulated Multi-field Tubular Flow Ensembles\",\"A Survey of Cardiac 4D PC-MRI Data Processing\",\"Recent Advances in MRI and Ultrasound Perfusion Imaging\",\"Motion-moderated Transfer Function for Volume Rendering 4D CMR Data\",\"InkVis: A High-Particle-Count Approach for Visualization of Phase-Contrast Magnetic Resonance Imaging Data\",\"Spatio-temporal Visualization of Regional Myocardial Velocities\",\"A Framework for Fast Initial Exploration of PC-MRI Cardiac Flow\",\"Semi-Automatic Vessel Boundary Detection in Cardiac 4D PC-MRI Data Using FTLE fields\",\"Temporal Interpolation of 4D PC-MRI Blood-flow Measurements Using Bidirectional Physics-based Fluid Simulation\",\"Glyph-Based Visualization of Myocardial Perfusion Data and Enhancement with Contractility and Viability Information\",\"Computation and Visualization of Asynchronous Behavior of the Heart\",\"Robust Cardiac Function Assessment in 4D PC-MRI Data\",\"CT Late Enhancement Segmentation for the Combined Analysis of Coronary Arteries and Myocardial Viability\",\"Exploration of Interventricular Septum Motion in Multi-Cycle Cardiac MRI\",\"Coherence Maps for Blood Flow Exploration\"],\"legendgroup\":\"flow.cardiac.pc.heart.4d.mri\",\"marker\":{\"color\":\"#FFA15A\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"flow.cardiac.pc.heart.4d.mri\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[4.669671058654785,3.589738368988037,3.5121471881866455,3.7888972759246826,4.913083076477051,3.7904462814331055,3.5362331867218018,4.021820545196533,3.650059461593628,4.007194519042969,4.623615741729736,3.920229911804199,3.4421820640563965,3.6616604328155518,4.071868419647217,4.885587692260742,3.653762102127075,3.9763846397399902,4.73019552230835,3.4849624633789062],\"xaxis\":\"x\",\"y\":[9.173772811889648,9.210819244384766,9.150259017944336,9.428169250488281,9.242599487304688,9.488009452819824,9.189637184143066,9.00275993347168,9.282461166381836,9.327967643737793,9.078448295593262,9.165833473205566,9.472344398498535,9.40076732635498,8.972015380859375,9.252713203430176,9.131651878356934,8.865918159484863,9.135003089904785,9.546984672546387],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"<b>%{hovertext}</b><br><br>Topics=valve.stress.implant.mitral.residual.bone<br>x=%{x}<br>y=%{y}<extra></extra>\",\"hovertext\":[\"Using Position-Based Dynamics for Simulating the Mitral Valve in a Decision Support System\",\"Projection Mapping for In-Situ Surgery Planning by the Example of DIEP Flap Breast Reconstruction\",\"Interactive Residual Stress Modeling for Soft Tissue Simulation\",\"VRIDAA: Virtual Reality Platform for Training and Planning Implantations of Occluder Devices in Left Atrial Appendages\",\"Computational Steering for Patient-Specific Implant Planning in Orthopedics\"],\"legendgroup\":\"valve.stress.implant.mitral.residual.bone\",\"marker\":{\"color\":\"#19d3f3\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"valve.stress.implant.mitral.residual.bone\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0.5959076881408691,0.7432489991188049,0.9978950023651123,0.7286272048950195,1.0789377689361572],\"xaxis\":\"x\",\"y\":[4.303058624267578,3.368222713470459,4.285902500152588,3.479966640472412,4.244519233703613],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"<b>%{hovertext}</b><br><br>Topics=fiber.tractography.crossing.tracts.diffusion.white<br>x=%{x}<br>y=%{y}<extra></extra>\",\"hovertext\":[\"The BundleExplorer: A Focus and Context Rendering Framework for Complex Fiber Distributions\",\"Progressive and Efficient Multi-Resolution Representations for Brain Tractograms\",\"Multi-fiber Estimation and Tractography for Diffusion MRI using mixture of Non-central Wishart Distributions\",\"Reducing Model Uncertainty in Crossing Fiber Tractography\",\"Visualizing White Matter Fiber Tracts with Optimally Fitted Curved Dissection Surfaces\",\"Fiber Stipples for Crossing Tracts in Probabilistic Tractography\",\"Accelerated Diffusion Operators for Enhancing DW-MRI\"],\"legendgroup\":\"fiber.tractography.crossing.tracts.diffusion.white\",\"marker\":{\"color\":\"#FF6692\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"fiber.tractography.crossing.tracts.diffusion.white\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[6.164465427398682,6.216649532318115,6.504331588745117,6.4561686515808105,6.247125148773193,6.279637336730957,6.563508987426758],\"xaxis\":\"x\",\"y\":[4.476739406585693,4.41409969329834,4.035645008087158,4.095235824584961,4.325950622558594,4.288823127746582,3.914127826690674],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverlabel\":{\"bgcolor\":\"#ffffff\",\"bordercolor\":\"#BDBDBD\",\"font\":{\"color\":\"#141414\",\"family\":\"Calibri\",\"size\":12}},\"hovertemplate\":\"<b>%{hovertext}<br></b><br>0=%{x}<br>1=%{y}\",\"hovertext\":[\"Pelvis Runner: Visualizing Pelvic Organ Variability in a Cohort of Radiotherapy Patients\",\"Information-based Transfer Functions for Multimodal Visualization\",\"Feasibility Study For Automatic Bird Tracking and Visualization from Time-Dependent Marine Radar Imagery\",\"CT-Based Navigation Guidance for Liver Tumor Ablation\",\"Design Considerations for Immersive Analytics of Bird Movements Obtained by Miniaturised GPS Sensors\",\"Sline: Seamless Line Illustration for Interactive Biomedical Visualization\",\"Estimation of Muscle Activity in One-Leg Stance from 3D Surface Deformation\",\"An Integrated Platform for Dynamic Cardiac Simulation and Image Processing: Application to Personalised Tetralogy of Fallot Simulation\",\"Medical Animations: A Survey and a Research Agenda\",\"Automatic Hepatocyte Quantification from Histological Images: Comparing Pre-smoothing filters\",\"Constrained Labeling of 2D Slice Data for Reading Images in Radiology\",\"Survey of Labeling Techniques in Medical Visualizations\",\"Tractography in Context: Multimodal Visualization of Probabilistic Tractograms in Anatomical Context\",\"A Web-based Application for the Visual Exploration of Colon Morphology Data\",\"Vologram: An Educational Holographic Sculpture for Volumetric Medical Data Physicalization\",\"The iCoCooN: Integration of Cobweb Charts with Parallel Coordinates for Visual Analysis of DCE-MRI Modeling Variations\",\"Personalized X-ray Reconstruction of the Proximal Femur via a New Control Point-based 2D-3D Registration and Residual Complexity Minimization\",\"Graxels: Information Rich Primitives for the Visualization of Time-Dependent Spatial Data\",\"Focus + Context Rendering of Structured Biomedical Data\",\"Interactive Real Time Simulation of Cardiac Radio-Frequency Ablation\",\"Illustrative PET/CT Visualisation of SIRT-Treated Lung Metastases\",\"Interactive Visualization of Muscle Activity During Limb Movements: Towards Enhanced Anatomy Learning\",\"Feature Exploration using Local Frequency Distributions in Computed Tomography Data\",\"Importance-Driven Structure Categorization for 3D Surgery Planning\",\"Interactive Position-dependent Customization of Transfer Function Classification Parameters in Volume Rendering\",\"Interactive Labeling of Toponome Data\"],\"marker\":{\"color\":\"#BDBDBD\"},\"mode\":\"markers\",\"name\":\"Selected\",\"showlegend\":false,\"x\":[6.848759174346924,5.211584091186523,4.70186710357666,1.534815788269043,4.56682014465332,5.74480676651001,1.3579542636871338,0.6152433156967163,1.0076299905776978,4.478983402252197,6.092660427093506,6.074634075164795,5.834123134613037,3.9063572883605957,1.0430923700332642,7.1601433753967285,2.2156052589416504,5.7240800857543945,6.076847553253174,0.5793965458869934,5.262200355529785,1.0082603693008423,5.730375289916992,6.099911212921143,5.159655570983887,9.93909740447998],\"y\":[1.5508618354797363,5.694760322570801,7.084474563598633,2.812906265258789,6.985806941986084,5.304762840270996,3.8656165599823,4.448028087615967,3.4530465602874756,1.8187189102172852,5.498110771179199,5.50588846206665,4.580630779266357,1.8577338457107544,3.2064671516418457,1.736873984336853,4.111143589019775,6.064004421234131,5.731310844421387,4.407580375671387,4.9625773429870605,3.715463876724243,6.088668346405029,5.658929824829102,5.83262300491333,5.841947078704834],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"x\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"y\"}},\"legend\":{\"title\":{\"text\":\"Topics\"},\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('0ed791fd-be4c-4702-a621-5a85632572f7');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                });            </script>        </div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 1440x720 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIkAAAJDCAYAAACPEUSwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAY00lEQVR4nO3dX8jl913g8feniVGotYKZBckkJuB0a7YK7Q7ZLr2w0O6S9CK50JUEilZC52Yj7lqEiFIlXlVZBSH+yWKpFmyMvZABI1nQSkFMyZS6oUmJDNFtJgqNteamtDG73714Hpen4yRzOnPO82yevF4wcH6/833O+dx8eWbe8zu/M2utAAAAAHh9e8NRDwAAAADA0ROJAAAAABCJAAAAABCJAAAAAEgkAgAAACCRCAAAAIA2iEQz89GZ+dLMfP4Vnp+Z+bWZOT8zT87MO7Y/JgAAAAC7tMmVRB+rbn+V5++oTu3/OVP9xtWPBQAAAMBhumwkWmt9uvqHV1lyV/W7a8/j1XfOzHdva0AAAAAAdm8b9yS6oXruwPGF/XMAAAAAvEZce5hvNjNn2vtIWm984xv/7Vvf+tbDfHsAAACAY+2zn/3s36+1TlzJz24jEj1f3Xjg+OT+uX9hrfVQ9VDV6dOn17lz57bw9gAAAABUzcz/utKf3cbHzc5WP7r/LWfvrF5ca/3dFl4XAAAAgENy2SuJZuYT1bur62fmQvXz1bdUrbV+s3q0el91vvpq9eO7GhYAAACA3bhsJFpr3XOZ51f1n7c2EQAAAACHbhsfNwMAAADgNU4kAgAAAEAkAgAAAEAkAgAAACCRCAAAAIBEIgAAAAASiQAAAABIJAIAAAAgkQgAAACARCIAAAAAEokAAAAASCQCAAAAIJEIAAAAgEQiAAAAABKJAAAAAEgkAgAAACCRCAAAAIBEIgAAAAASiQAAAABIJAIAAAAgkQgAAACARCIAAAAAEokAAAAASCQCAAAAIJEIAAAAgEQiAAAAABKJAAAAAEgkAgAAACCRCAAAAIBEIgAAAAASiQAAAABIJAIAAAAgkQgAAACARCIAAAAAEokAAAAASCQCAAAAIJEIAAAAgEQiAAAAABKJAAAAAEgkAgAAACCRCAAAAIBEIgAAAAASiQAAAABIJAIAAAAgkQgAAACARCIAAAAAEokAAAAASCQCAAAAIJEIAAAAgEQiAAAAABKJAAAAAEgkAgAAACCRCAAAAIBEIgAAAAASiQAAAABIJAIAAAAgkQgAAACARCIAAAAAEokAAAAASCQCAAAAIJEIAAAAgEQiAAAAABKJAAAAAEgkAgAAACCRCAAAAIBEIgAAAAASiQAAAABIJAIAAAAgkQgAAACARCIAAAAAEokAAAAASCQCAAAAIJEIAAAAgEQiAAAAABKJAAAAAEgkAgAAACCRCAAAAIBEIgAAAAASiQAAAABIJAIAAAAgkQgAAACARCIAAAAAEokAAAAASCQCAAAAIJEIAAAAgEQiAAAAABKJAAAAAEgkAgAAACCRCAAAAIBEIgAAAAASiQAAAABIJAIAAAAgkQgAAACARCIAAAAAEokAAAAASCQCAAAAIJEIAAAAgEQiAAAAABKJAAAAAEgkAgAAAKANI9HM3D4zz8zM+Zm5/xLP3zQzn5qZz83MkzPzvu2PCgAAAMCuXDYSzcw11YPVHdWt1T0zc+tFy36uemSt9fbq7urXtz0oAAAAALuzyZVEt1Xn11rPrrVeqh6u7rpozaq+Y//xm6u/3d6IAAAAAOzatRusuaF67sDxherfXbTmF6r/MTM/Ub2xeu9WpgMAAADgUGzrxtX3VB9ba52s3ld9fGb+xWvPzJmZOTcz51544YUtvTUAAAAAV2uTSPR8deOB45P75w66t3qkaq31F9W3Vddf/EJrrYfWWqfXWqdPnDhxZRMDAAAAsHWbRKInqlMzc8vMXNfejanPXrTmi9V7qmbm+9qLRC4VAgAAAHiNuGwkWmu9XN1XPVZ9ob1vMXtqZh6YmTv3l32o+uDM/M/qE9UH1lprV0MDAAAAsF2b3Li6tdaj1aMXnfvwgcdPV+/a7mgAAAAAHJZt3bgaAAAAgNcwkQgAAAAAkQgAAAAAkQgAAACARCIAAAAAEokAAAAASCQCAAAAIJEIAAAAgEQiAAAAABKJAAAAAEgkAgAAACCRCAAAAIBEIgAAAAASiQAAAABIJAIAAAAgkQgAAACARCIAAAAAEokAAAAASCQCAAAAIJEIAAAAgEQiAAAAABKJAAAAAEgkAgAAACCRCAAAAIBEIgAAAAASiQAAAABIJAIAAAAgkQgAAACARCIAAAAAEokAAAAASCQCAAAAIJEIAAAAgEQiAAAAABKJAAAAAEgkAgAAACCRCAAAAIBEIgAAAAASiQAAAABIJAIAAAAgkQgAAACARCIAAAAAEokAAAAASCQCAAAAIJEIAAAAgEQiAAAAABKJAAAAAEgkAgAAACCRCAAAAIBEIgAAAAASiQAAAABIJAIAAAAgkQgAAACARCIAAAAAEokAAAAASCQCAAAAIJEIAAAAgEQiAAAAABKJAAAAAEgkAgAAACCRCAAAAIBEIgAAAAASiQAAAABIJAIAAAAgkQgAAACARCIAAAAAEokAAAAASCQCAAAAIJEIAAAAgEQiAAAAABKJAAAAAEgkAgAAACCRCAAAAIBEIgAAAAASiQAAAABIJAIAAAAgkQgAAACARCIAAAAAEokAAAAASCQCAAAAIJEIAAAAgEQiAAAAABKJAAAAAEgkAgAAACCRCAAAAIBEIgAAAAASiQAAAABIJAIAAAAgkQgAAACARCIAAAAAEokAAAAASCQCAAAAIJEIAAAAgEQiAAAAABKJAAAAAEgkAgAAACCRCAAAAIBEIgAAAAASiQAAAABIJAIAAAAgkQgAAACANoxEM3P7zDwzM+dn5v5XWPMjM/P0zDw1M7+33TEBAAAA2KVrL7dgZq6pHqz+Q3WhemJmzq61nj6w5lT1M9W71lpfmZl/tauBAQAAANi+Ta4kuq06v9Z6dq31UvVwdddFaz5YPbjW+krVWutL2x0TAAAAgF3aJBLdUD134PjC/rmD3lK9ZWb+fGYen5nbtzUgAAAAALt32Y+bfROvc6p6d3Wy+vTMfP9a6x8PLpqZM9WZqptuumlLbw0AAADA1drkSqLnqxsPHJ/cP3fQhersWuuf1lp/Xf1Ve9HoG6y1HlprnV5rnT5x4sSVzgwAAADAlm0SiZ6oTs3MLTNzXXV3dfaiNX/Y3lVEzcz17X387NntjQkAAADALl02Eq21Xq7uqx6rvlA9stZ6amYemJk795c9Vn15Zp6uPlX99Frry7saGgAAAIDtmrXWkbzx6dOn17lz547kvQEAAACOo5n57Frr9JX87CYfNwMAAADgmBOJAAAAABCJAAAAABCJAAAAAEgkAgAAACCRCAAAAIBEIgAAAAASiQAAAABIJAIAAAAgkQgAAACARCIAAAAAEokAAAAASCQCAAAAIJEIAAAAgEQiAAAAABKJAAAAAEgkAgAAACCRCAAAAIBEIgAAAAASiQAAAABIJAIAAAAgkQgAAACARCIAAAAAEokAAAAASCQCAAAAIJEIAAAAgEQiAAAAABKJAAAAAEgkAgAAACCRCAAAAIBEIgAAAAASiQAAAABIJAIAAAAgkQgAAACARCIAAAAAEokAAAAASCQCAAAAIJEIAAAAgEQiAAAAABKJAAAAAEgkAgAAACCRCAAAAIBEIgAAAAASiQAAAABIJAIAAAAgkQgAAACARCIAAAAAEokAAAAASCQCAAAAIJEIAAAAgEQiAAAAABKJAAAAAEgkAgAAACCRCAAAAIBEIgAAAAASiQAAAABIJAIAAAAgkQgAAACARCIAAAAAEokAAAAASCQCAAAAIJEIAAAAgEQiAAAAABKJAAAAAEgkAgAAACCRCAAAAIBEIgAAAAASiQAAAABIJAIAAAAgkQgAAACARCIAAAAAEokAAAAASCQCAAAAIJEIAAAAgEQiAAAAABKJAAAAAEgkAgAAACCRCAAAAIBEIgAAAAASiQAAAABIJAIAAAAgkQgAAACARCIAAAAAEokAAAAASCQCAAAAIJEIAAAAgEQiAAAAABKJAAAAAEgkAgAAACCRCAAAAIBEIgAAAAASiQAAAABIJAIAAAAgkQgAAACARCIAAAAAEokAAAAASCQCAAAAIJEIAAAAgEQiAAAAANowEs3M7TPzzMycn5n7X2XdD83MmpnT2xsRAAAAgF27bCSamWuqB6s7qlure2bm1kuse1P1k9Vntj0kAAAAALu1yZVEt1Xn11rPrrVeqh6u7rrEul+sPlJ9bYvzAQAAAHAINolEN1TPHTi+sH/u/5mZd1Q3rrX+aIuzAQAAAHBIrvrG1TPzhupXqg9tsPbMzJybmXMvvPDC1b41AAAAAFuySSR6vrrxwPHJ/XP/7E3V26o/m5m/qd5Znb3UzavXWg+ttU6vtU6fOHHiyqcGAAAAYKs2iURPVKdm5paZua66uzr7z0+utV5ca12/1rp5rXVz9Xh151rr3E4mBgAAAGDrLhuJ1lovV/dVj1VfqB5Zaz01Mw/MzJ27HhAAAACA3bt2k0VrrUerRy869+FXWPvuqx8LAAAAgMN01TeuBgAAAOC1TyQCAAAAQCQCAAAAQCQCAAAAIJEIAAAAgEQiAAAAABKJAAAAAEgkAgAAACCRCAAAAIBEIgAAAAASiQAAAABIJAIAAAAgkQgAAACARCIAAAAAEokAAAAASCQCAAAAIJEIAAAAgEQiAAAAABKJAAAAAEgkAgAAACCRCAAAAIBEIgAAAAASiQAAAABIJAIAAAAgkQgAAACARCIAAAAAEokAAAAASCQCAAAAIJEIAAAAgEQiAAAAABKJAAAAAEgkAgAAACCRCAAAAIBEIgAAAAASiQAAAABIJAIAAAAgkQgAAACARCIAAAAAEokAAAAASCQCAAAAIJEIAAAAgEQiAAAAABKJAAAAAEgkAgAAACCRCAAAAIBEIgAAAAASiQAAAABIJAIAAAAgkQgAAACARCIAAAAAEokAAAAASCQCAAAAIJEIAAAAgEQiAAAAABKJAAAAAEgkAgAAACCRCAAAAIBEIgAAAAASiQAAAABIJAIAAAAgkQgAAACARCIAAAAAEokAAAAASCQCAAAAIJEIAAAAgEQiAAAAABKJAAAAAEgkAgAAACCRCAAAAIBEIgAAAAASiQAAAABIJAIAAAAgkQgAAACARCIAAAAAEokAAAAASCQCAAAAIJEIAAAAgEQiAAAAABKJAAAAAEgkAgAAACCRCAAAAIBEIgAAAAASiQAAAABIJAIAAAAgkQgAAACARCIAAAAAEokAAAAASCQCAAAAIJEIAAAAgEQiAAAAABKJAAAAAEgkAgAAACCRCAAAAIBEIgAAAAASiQAAAABIJAIAAAAgkQgAAACARCIAAAAAEokAAAAASCQCAAAAoA0j0czcPjPPzMz5mbn/Es//1Mw8PTNPzsyfzMz3bH9UAAAAAHblspFoZq6pHqzuqG6t7pmZWy9a9rnq9FrrB6pPVr+07UEBAAAA2J1NriS6rTq/1np2rfVS9XB118EFa61PrbW+un/4eHVyu2MCAAAAsEubRKIbqucOHF/YP/dK7q3++GqGAgAAAOBwXbvNF5uZ91enqx98hefPVGeqbrrppm2+NQAAAABXYZMriZ6vbjxwfHL/3DeYmfdWP1vdudb6+qVeaK310Frr9Frr9IkTJ65kXgAAAAB2YJNI9ER1amZumZnrqrurswcXzMzbq99qLxB9aftjAgAAALBLl41Ea62Xq/uqx6ovVI+stZ6amQdm5s79Zb9cfXv1BzPzlzNz9hVeDgAAAID/D210T6K11qPVoxed+/CBx+/d8lwAAAAAHKJNPm4GAAAAwDEnEgEAAAAgEgEAAAAgEgEAAACQSAQAAABAIhEAAAAAiUQAAAAAJBIBAAAAkEgEAAAAQCIRAAAAAIlEAAAAACQSAQAAAJBIBAAAAEAiEQAAAACJRAAAAAAkEgEAAACQSAQAAABAIhEAAAAAiUQAAAAAJBIBAAAAkEgEAAAAQCIRAAAAAIlEAAAAACQSAQAAAJBIBAAAAEAiEQAAAACJRAAAAAAkEgEAAACQSAQAAABAIhEAAAAAiUQAAAAAJBIBAAAAkEgEAAAAQCIRAAAAAIlEAAAAACQSAQAAAJBIBAAAAEAiEQAAAACJRAAAAAAkEgEAAACQSAQAAABAIhEAAAAAiUQAAAAAJBIBAAAAkEgEAAAAQCIRAAAAAIlEAAAAACQSAQAAAJBIBAAAAEAiEQAAAACJRAAAAAAkEgEAAACQSAQAAABAIhEAAAAAiUQAAAAAJBIBAAAAkEgEAAAAQCIRAAAAAIlEAAAAACQSAQAAAJBIBAAAAEAiEQAAAACJRAAAAAAkEgEAAACQSAQAAABAIhEAAAAAiUQAAAAAJBIBAAAAkEgEAAAAQCIRAAAAAIlEAAAAACQSAQAAAJBIBAAAAEAiEQAAAACJRAAAAAAkEgEAAACQSAQAAABAIhEAAAAAiUQAAAAAJBIBAAAAkEgEAAAAQCIRAAAAAIlEAAAAACQSAQAAAJBIBAAAAEAiEQAAAACJRAAAAAAkEgEAAACQSAQAAABAIhEAAAAAiUQAAAAAJBIBAAAAkEgEAAAAQCIRAAAAAIlEAAAAACQSAQAAAJBIBAAAAEAiEQAAAACJRAAAAAAkEgEAAADQhpFoZm6fmWdm5vzM3H+J5791Zn5///nPzMzNW58UAAAAgJ25bCSamWuqB6s7qlure2bm1ouW3Vt9Za31vdWvVh/Z9qAAAAAA7M4mVxLdVp1faz271nqperi666I1d1W/s//4k9V7Zma2NyYAAAAAu7RJJLqheu7A8YX9c5dcs9Z6uXqx+q5tDAgAAADA7l17mG82M2eqM/uHX5+Zzx/m+wNVXV/9/VEPAa9D9h4cHfsPjoa9B0fjX1/pD24SiZ6vbjxwfHL/3KXWXJiZa6s3V1+++IXWWg9VD1XNzLm11ukrGRq4cvYeHA17D46O/QdHw96DozEz5670Zzf5uNkT1amZuWVmrqvurs5etOZs9WP7j3+4+tO11rrSoQAAAAA4XJe9kmit9fLM3Fc9Vl1TfXSt9dTMPFCdW2udrX67+vjMnK/+ob2QBAAAAMBrxEb3JFprPVo9etG5Dx94/LXqP32T7/3QN7ke2A57D46GvQdHx/6Do2HvwdG44r03PhUGAAAAwCb3JAIAAADgmNt5JJqZ22fmmZk5PzP3X+L5b52Z399//jMzc/OuZ4LXgw323k/NzNMz8+TM/MnMfM9RzAnHzeX23oF1PzQza2Z86wtswSZ7b2Z+ZP9331Mz83uHPSMcVxv8vfOmmfnUzHxu/++e7zuKOeE4mZmPzsyXZubzr/D8zMyv7e/LJ2fmHZu87k4j0cxcUz1Y3VHdWt0zM7detOze6itrre+tfrX6yC5ngteDDffe56rTa60fqD5Z/dLhTgnHz4Z7r5l5U/WT1WcOd0I4njbZezNzqvqZ6l1rrX9T/ZfDnhOOow1/9/1c9cha6+3tfcnRrx/ulHAsfay6/VWev6M6tf/nTPUbm7zorq8kuq06v9Z6dq31UvVwdddFa+6qfmf/8Ser98zM7HguOO4uu/fWWp9aa311//Dx6uQhzwjH0Sa/96p+sb3/FPnaYQ4Hx9gme++D1YNrra9UrbW+dMgzwnG1yf5b1XfsP35z9beHOB8cS2utT7f37fKv5K7qd9eex6vvnJnvvtzr7joS3VA9d+D4wv65S65Za71cvVh9147nguNuk7130L3VH+90Inh9uOze27/U98a11h8d5mBwzG3ye+8t1Vtm5s9n5vGZebX/fQU2t8n++4Xq/TNzob1vzf6JwxkNXte+2X8TVnXtzsYBXhNm5v3V6eoHj3oWOO5m5g3Vr1QfOOJR4PXo2vYuuX93e1fPfnpmvn+t9Y9HORS8TtxTfWyt9d9m5t9XH5+Zt621/s9RDwZ8o11fSfR8deOB45P75y65Zmaube/ywy/veC447jbZe83Me6ufre5ca339kGaD4+xye+9N1duqP5uZv6neWZ1182q4apv83rtQnV1r/dNa66+rv2ovGgFXZ5P9d2/1SNVa6y+qb6uuP5Tp4PVro38TXmzXkeiJ6tTM3DIz17V3k7KzF605W/3Y/uMfrv50rbV2PBccd5fdezPz9uq32gtE7ssA2/Gqe2+t9eJa6/q11s1rrZvbux/YnWutc0czLhwbm/yd8w/bu4qombm+vY+fPXuIM8Jxtcn++2L1nqqZ+b72ItELhzolvP6crX50/1vO3lm9uNb6u8v90E4/brbWenlm7qseq66pPrrWempmHqjOrbXOVr/d3uWG59u76dLdu5wJXg823Hu/XH179Qf794r/4lrrziMbGo6BDfcesGUb7r3Hqv84M09X/7v66bWWq9fhKm24/z5U/feZ+a/t3cT6Ay4MgKszM59o7z8/rt+/39fPV99Stdb6zfbu//W+6nz11erHN3pdexMAAACAXX/cDAAAAIDXAJEIAAAAAJEIAAAAAJEIAAAAgEQiAAAAABKJAAAAAEgkAgAAACCRCAAAAIDq/wL8+K5CHpV7DQAAAABJRU5ErkJggg==\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "top_n_words = extract_top_n_words_per_topic(tf_idf, count, docs_per_topic, n=6)\n",
    "print(top_n_words)\n",
    "from collections import Counter\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "\n",
    "# Visualize clusters\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "outliers = result.loc[result.labels == -1, :]\n",
    "clustered = result.loc[result.labels != -1, :]\n",
    "\n",
    "plot_top=Counter() # to get only distinct labels, replace with a set and add a check here [1]\n",
    "top_terms = top_n_words\n",
    "\n",
    "\n",
    "top_terms_docs = ['.'.join(str(e) for e in top_terms[item]) for item in clustered.labels]\n",
    "print(len(top_terms_docs))\n",
    "\n",
    "\n",
    "# ax.scatter(outliers.x, outliers.y, color='#BDBDBD')\n",
    "# print(\"clustered labels\", clustered.labels)\n",
    "# ax.scatter(clustered.x, clustered.y, c=clustered.labels, cmap='hsv_r')\n",
    "#\n",
    "#\n",
    "# for i, lab, prob in zip(range(len(cluster.labels_)),cluster.labels_, cluster.probabilities_): # pointwise iteration\n",
    "#         print(\"lab\", lab)\n",
    "#         print(\"i: \",i)\n",
    "#         if lab != -1:\n",
    "#             for el in top_terms[lab][:5]:\n",
    "#                     print(i)\n",
    "#                     # x[i], y[i] are the projected points in 2D space\n",
    "#                     ax.annotate(el, (clustered.x[i],clustered.y[i]))\n",
    "#                     break\n",
    "\n",
    "\n",
    "import plotly.express as px\n",
    "df = px.data.iris()\n",
    "fig = px.scatter(x=clustered.x, y=clustered.y, color=top_terms_docs, hover_name=clustered.titles,\n",
    "                 labels={\"color\" : \"Topics\"})\n",
    "fig.add_trace(go.Scatter(x=outliers.x, y=outliers.y, mode='markers', showlegend=False, hovertext=outliers.titles,\n",
    "                                     name='Selected',\n",
    "                                     marker=dict(\n",
    "                                         color='#BDBDBD',\n",
    "                                     ),\n",
    "                                     hoverlabel=dict(\n",
    "                                         bgcolor=\"#ffffff\",\n",
    "                                         font_size=12,\n",
    "                                         font_color=\"#141414\",\n",
    "                                         font_family=\"Calibri\",\n",
    "                                         bordercolor=\"#BDBDBD\",\n",
    "                                     ),\n",
    "                                    hovertemplate='<b>%{hovertext}<br></b><br>0=%{x}<br>1=%{y}'\n",
    "                                     ))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "outputs": [
    {
     "data": {
      "text/plain": "    Topic  Size\n0      -1    37\n2       1    29\n17     16    25\n1       0    21\n10      9    14\n19     18    13\n7       6    11\n8       7    10\n11     10    10\n13     12    10\n3       2     8\n4       3     7\n12     11     7\n16     15     7\n5       4     5\n6       5     5\n9       8     5\n15     14     5\n18     17     4\n14     13     3",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Topic</th>\n      <th>Size</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1</td>\n      <td>37</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>16</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>9</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>18</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>6</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>7</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>10</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>12</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>11</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>15</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>4</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>5</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>8</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>14</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>17</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>13</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_sizes = extract_topic_sizes(docs_df)\n",
    "topic_sizes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "outputs": [
    {
     "data": {
      "text/plain": "['rib', 'segmentation', 'radiation', 'pelvic', 'segmentations', 'automatic']"
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_n_words[15]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [
    {
     "data": {
      "text/plain": "[('ar', 0.014906447694789392),\n ('ultrasound', 0.014830173224860466),\n ('ray', 0.014435801652078747),\n ('hmd', 0.01333682446415577),\n ('haptics', 0.01333682446415577),\n ('gesture', 0.01333682446415577),\n ('biopsy', 0.012776955166962338),\n ('tracing', 0.011864190899598271),\n ('sln', 0.011665841079272123),\n ('touch', 0.011665841079272123)]"
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_n_words[15][:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "data": {
      "text/plain": "[('vascular', 0.023594408403621776),\n ('depth', 0.019329315590091947),\n ('vessel', 0.018631478036349774),\n ('tree', 0.017012707911122842),\n ('parameterization', 0.016555582224809098),\n ('vessels', 0.015975638281646127),\n ('xr', 0.015462662539558077),\n ('stress', 0.015023520622326635),\n ('blood', 0.014883646310110462),\n ('color', 0.013910985269266455)]"
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_n_words[10][:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model1 = SentenceTransformer('allenai-specter')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'docvec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [2]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m result,cluster, docs, docs_df, docs_per_topic \u001B[38;5;241m=\u001B[39m \u001B[43mdocvec\u001B[49m(model1)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'docvec' is not defined"
     ]
    }
   ],
   "source": [
    "result,cluster, docs, docs_df, docs_per_topic = docvec(model1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "\n",
    "tf_idf, count = c_tf_idf(docs_per_topic.Doc.values, m=len(docs))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "\n",
    "top_n_words = extract_top_n_words_per_topic(tf_idf, count, docs_per_topic, n=20)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{-1: ['vessels', 'stress', 'neck', 'hifu', 'residual', 'colon', 'vessel', 'blood', 'lumen', 'wall'], 0: ['protein', 'molecular', 'proteins', 'cell', 'tunnels', 'molecules', 'properties', 'molecule', 'tunnel', 'level'], 1: ['fiber', 'diffusion', 'brain', 'connectivity', 'tensor', 'tractography', 'functional', 'crossing', 'neurons', 'tracts'], 2: ['analytics', 'sleep', 'rehabilitation', 'biomedical', 'communication', 'discovery', 'knowledge', 'staging', 'models', 'notes'], 3: ['evaluations', 'evaluation', 'studies', 'perception', 'user', 'surfaces', 'visualizations', 'aneurysm', 'web', 'medical'], 4: ['deep', 'pathologists', 'pathology', 'digital', 'learning', 'diagnostic', 'mitotic', 'mammogram', 'mg', 'classification'], 5: ['reality', 'virtual', 'vr', 'valve', 'training', 'mitral', 'haptic', 'interaction', 'simulation', 'xr'], 6: ['vascular', 'bird', 'vessel', 'parameterization', 'radar', 'depth', 'color', 'dependent', 'applicator', 'animation'], 7: ['registration', 'implant', 'motion', 'bone', 'stage', 'lung', 'simulation', 'specific', '2d', 'prediction'], 8: ['heart', 'motion', 'regional', 'myocardial', 'lv', 'spatio', 'ventricle', 'cardiac', 'temporal', 'cycle'], 9: ['smoothing', 'mesh', 'surface', 'shape', 'deformation', 'noise', 'statistical', 'mgs', 'skeleton', 'matches'], 10: ['flow', 'pc', '4d', 'mri', 'aortic', 'blood', 'perfusion', 'cfd', 'pathlines', 'cardiac'], 11: ['transfer', 'projection', 'distortions', 'mutual', 'projections', 'multimodal', 'volume', 'function', 'wdt', 'registrationshop'], 12: ['ultrasound', 'tumor', 'liver', 'ius', 'interventional', 'registered', 'fetus', 'intraoperative', 'ablation', 'hifupm'], 13: ['pet', 'uncertainty', 'modeling', 'thermal', 'rib', 'labels', 'ct', 'labeling', 'visualisation', 'cocoon'], 14: ['cow', 'tof', 'pathological', 'skull', 'cerebral', 'sequences', 'arteries', 'stripping', 'mra', 'tumors'], 15: ['arteries', 'artery', 'cta', 'coronary', 'thrombus', 'automated', 'ischemic', 'angiography', 'cerebral', 'content']}\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1440x720 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "top_n_words = extract_top_n_words_per_topic(tf_idf, count, docs_per_topic, n=10)\n",
    "print(top_n_words)\n",
    "from collections import Counter\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Visualize clusters\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "outliers = result.loc[result.labels == -1, :]\n",
    "clustered = result.loc[result.labels != -1, :]\n",
    "pio.renderers.default = \"browser\"\n",
    "plot_top=Counter() # to get only distinct labels, replace with a set and add a check here [1]\n",
    "top_terms = top_n_words\n",
    "\n",
    "\n",
    "top_terms_docs = ['.'.join(str(e) for e in top_terms[item]) for item in clustered.labels]\n",
    "\n",
    "\n",
    "\n",
    "fig = px.scatter(x=clustered.x, y=clustered.y, color=top_terms_docs, hover_name=clustered.titles,\n",
    "                 labels={\"color\" : \"Topics\"})\n",
    "fig.add_trace(go.Scatter(x=outliers.x, y=outliers.y, mode='markers', showlegend=False, hovertext=outliers.titles,\n",
    "                                     name='Selected',\n",
    "                                     marker=dict(\n",
    "                                         color='#BDBDBD',\n",
    "                                     ),\n",
    "                                     hoverlabel=dict(\n",
    "                                         bgcolor=\"#ffffff\",\n",
    "                                         font_size=12,\n",
    "                                         font_color=\"#141414\",\n",
    "                                         font_family=\"Calibri\",\n",
    "                                         bordercolor=\"#BDBDBD\",\n",
    "                                     ),\n",
    "                                    hovertemplate='<b>%{hovertext}<br></b><br>0=%{x}<br>1=%{y}'\n",
    "                                     ))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "outputs": [
    {
     "data": {
      "text/plain": "    Topic  Size\n0      -1    37\n2       1    29\n17     16    25\n1       0    21\n10      9    14\n19     18    13\n7       6    11\n8       7    10\n11     10    10\n13     12    10\n3       2     8\n4       3     7\n12     11     7\n16     15     7\n5       4     5\n6       5     5\n9       8     5\n15     14     5\n18     17     4\n14     13     3",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Topic</th>\n      <th>Size</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1</td>\n      <td>37</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>16</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>9</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>18</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>6</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>7</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>10</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>12</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>11</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>15</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>4</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>5</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>8</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>14</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>17</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>13</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_sizes = extract_topic_sizes(docs_df)\n",
    "topic_sizes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [
    {
     "data": {
      "text/plain": "[('fiber', 0.032929810190857195),\n ('diffusion', 0.031988310329731),\n ('tensor', 0.023774861157086494),\n ('tractography', 0.02289201984294166),\n ('crossing', 0.020034806920963825),\n ('tracts', 0.017929453404837658),\n ('matter', 0.014394004309817222),\n ('white', 0.014394004309817222),\n ('dti', 0.013091680803717212),\n ('uncertainty', 0.013039795921343819)]"
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_n_words[1][:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "topic_sizes = extract_topic_sizes(docs_df)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def c_tf_idf(documents, m, ngram_range=(1, 1)):\n",
    "    count = CountVectorizer(ngram_range=ngram_range, stop_words=\"english\").fit(documents)\n",
    "    t = count.transform(documents).toarray()\n",
    "    w = t.sum(axis=1)\n",
    "    tf = np.divide(t.T, w)\n",
    "    sum_t = t.sum(axis=0)\n",
    "    idf = np.log(np.divide(m, sum_t)).reshape(-1, 1)\n",
    "    tf_idf = np.multiply(tf, idf)\n",
    "\n",
    "    return tf_idf, count"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def docvec():\n",
    "    docs = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))['data']\n",
    "    docs = docs[0:100]\n",
    "\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    embeddings = model.encode(docs, show_progress_bar=True)\n",
    "    print(embeddings)\n",
    "\n",
    "    umap_embeddings = umap.UMAP(n_neighbors=5,\n",
    "                                n_components=5,\n",
    "                                metric='cosine').fit_transform(embeddings)\n",
    "\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=5,\n",
    "                              metric='euclidean',\n",
    "                              cluster_selection_method='eom').fit(umap_embeddings)\n",
    "    print(cluster)\n",
    "\n",
    "\n",
    "\n",
    "    # Prepare data\n",
    "    umap_data = umap.UMAP(n_neighbors=15, n_components=2, min_dist=0.0, metric='cosine').fit_transform(embeddings)\n",
    "    result = pd.DataFrame(umap_data, columns=['x', 'y'])\n",
    "    result['labels'] = cluster.labels_\n",
    "    print(result['labels'])\n",
    "\n",
    "    # Visualize clusters\n",
    "    fig, ax = plt.subplots(figsize=(20, 10))\n",
    "    outliers = result.loc[result.labels == -1, :]\n",
    "    clustered = result.loc[result.labels != -1, :]\n",
    "    plt.scatter(outliers.x, outliers.y, color='#BDBDBD', s=0.05)\n",
    "    plt.scatter(clustered.x, clustered.y, c=clustered.labels, s=0.05, cmap='hsv_r')\n",
    "    plt.colorbar()\n",
    "\n",
    "    docs_df = pd.DataFrame(docs, columns=[\"Doc\"])\n",
    "    docs_df['Topic'] = cluster.labels_\n",
    "    docs_df['Doc_ID'] = range(len(docs_df))\n",
    "    docs_per_topic = docs_df.groupby(['Topic'], as_index=False).agg({'Doc': ' '.join})\n",
    "    return docs, docs_df, docs_per_topic"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}